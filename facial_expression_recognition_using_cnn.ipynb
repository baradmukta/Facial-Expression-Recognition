{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/baradmukta/Facial-Expression-Recognition-Open-CV/blob/main/facial_expression_recognition_using_cnn.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5z8nt9uSJkGr"
      },
      "source": [
        "# Facial Expression Recognition Using CNN"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ITK54PhVBAry"
      },
      "source": [
        "**Facial Expression Recognition** using a **Convolutional Neural Network** delves into the process of interpreting human emotions from images. This tutorial walks you through dataset exploration, model development, training, and evaluation. You'll learn how to design a convolutional neural network and train it to recognize emotions such as happiness and sadness."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cMRASQYfBhXM"
      },
      "source": [
        "### **Import Libraries**\n",
        "\n",
        "This section imports the essential libraries needed for constructing and training a convolutional neural network (CNN) for facial expression recognition.\n",
        "\n",
        "- `os`: Provides functions to interact with the operating system, useful for handling file operations.\n",
        "- `cv2`: OpenCV library for computer vision, used here for processing images.\n",
        "- `numpy`: A library for numerical computing, essential for array manipulations.\n",
        "- `tensorflow`: The TensorFlow library used for deep learning tasks.\n",
        "- `train_test_split` from `sklearn.model_selection`: Splits the dataset into training and testing subsets.\n",
        "- `ImageDataGenerator` from `tensorflow.keras.preprocessing.image`: Generates batches of augmented data for training.\n",
        "- `LabelEncoder` from `sklearn.preprocessing`: Converts categorical labels into numerical format.\n",
        "- `to_categorical` from `keras.utils`: Transforms class labels into a binary class matrix.\n",
        "- `Sequential` from `keras.models`: A linear stack of layers used to build deep learning models.\n",
        "- `Dense`, `Conv2D`, `Dropout`, `BatchNormalization`, `MaxPooling2D`, `Flatten` from `keras.layers`: Various layers used in the CNN architecture.\n",
        "- Optimizers (`Adam`, `RMSprop`, `SGD`) from `keras.optimizers`: Algorithms that adjust model weights during training.\n",
        "- `plt` from `matplotlib.pyplot`: A plotting library for visualizing training and validation curves.\n",
        "- Callbacks (`ModelCheckpoint`, `EarlyStopping`, `ReduceLROnPlateau`) from `keras.callbacks`: Tools used during training to enhance model performance or handle interruptions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-07T16:13:25.188297Z",
          "iopub.status.busy": "2024-08-07T16:13:25.187881Z",
          "iopub.status.idle": "2024-08-07T16:13:38.898988Z",
          "shell.execute_reply": "2024-08-07T16:13:38.898206Z",
          "shell.execute_reply.started": "2024-08-07T16:13:25.188266Z"
        },
        "id": "fDYyQlK_iMSL",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, Dropout, BatchNormalization, MaxPooling2D, Flatten\n",
        "from keras.optimizers import Adam, RMSprop, SGD\n",
        "import matplotlib.pyplot as plt\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up Data directory"
      ],
      "metadata": {
        "id": "EAzrazMGUrvi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Setting up directory of kaggle name"
      ],
      "metadata": {
        "id": "mewnOpUzhvJv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "''' step 1 go to kaggle --> profile --> settings --> create new token -->\n",
        " kaggle.json file will be downloaded --> upload that file collab drive\n",
        " '''\n",
        "!mkdir -p ./kaggle\n",
        "!cp kaggle.json ~/.kaggle/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmiFMyolf5CF",
        "outputId": "a742b9dd-14ad-4a03-ce3e-c379b1a3a7d4"
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cp: cannot create regular file '/root/.kaggle/': Not a directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d msambare/fer2013"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFjuqi1FgeMP",
        "outputId": "552ae428-b474-42ea-cbbd-dc73c1bf0474"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/msambare/fer2013\n",
            "License(s): DbCL-1.0\n",
            "fer2013.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/fer2013.zip -d /content/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "io7_gHZugqJS",
        "outputId": "d5ae4b47-493e-4129-bc2d-88337e269975"
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/fer2013.zip\n",
            "replace /content/test/angry/PrivateTest_10131363.jpg? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-07T16:13:38.901048Z",
          "iopub.status.busy": "2024-08-07T16:13:38.900534Z",
          "iopub.status.idle": "2024-08-07T16:13:38.905051Z",
          "shell.execute_reply": "2024-08-07T16:13:38.904131Z",
          "shell.execute_reply.started": "2024-08-07T16:13:38.901022Z"
        },
        "id": "Q9L2Lx6dib9F",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Dataset Directory\n",
        "data_dir = \"/content/train\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-07T16:13:38.906401Z",
          "iopub.status.busy": "2024-08-07T16:13:38.906079Z",
          "iopub.status.idle": "2024-08-07T16:13:38.977864Z",
          "shell.execute_reply": "2024-08-07T16:13:38.976939Z",
          "shell.execute_reply.started": "2024-08-07T16:13:38.906376Z"
        },
        "id": "gWafwx62ilRE",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Classes\n",
        "sub_folders = os.listdir(data_dir)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-07T16:13:38.980114Z",
          "iopub.status.busy": "2024-08-07T16:13:38.979772Z",
          "iopub.status.idle": "2024-08-07T16:13:38.984423Z",
          "shell.execute_reply": "2024-08-07T16:13:38.983539Z",
          "shell.execute_reply.started": "2024-08-07T16:13:38.980066Z"
        },
        "id": "OBRZU_fzisqq",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Declaring the lists for images and labels\n",
        "images = []\n",
        "labels = []"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-07T16:13:38.987623Z",
          "iopub.status.busy": "2024-08-07T16:13:38.987313Z",
          "iopub.status.idle": "2024-08-07T16:16:08.423668Z",
          "shell.execute_reply": "2024-08-07T16:16:08.422808Z",
          "shell.execute_reply.started": "2024-08-07T16:13:38.987601Z"
        },
        "id": "6N7TZ54civYK",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Accessing the labels\n",
        "for sub_folder in sub_folders:\n",
        "    label = sub_folder\n",
        "\n",
        "    # Constructing the path to the current sub-folder\n",
        "    path = os.path.join(data_dir, sub_folder)\n",
        "\n",
        "    # Listing all images in the current sub-folder\n",
        "    sub_folder_images = os.listdir(path)\n",
        "\n",
        "    # Accessing the Images\n",
        "    for image_name in sub_folder_images:\n",
        "        # Constructing the path to the current image\n",
        "        image_path = os.path.join(path, image_name)\n",
        "        # Loading the image using OpenCV\n",
        "        img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)  # Read as grayscale\n",
        "        # Appending the image to the list of images\n",
        "        images.append(img)\n",
        "        # Appending the label corresponding to the current sub-folder to the list of labels\n",
        "        labels.append(label)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-07T16:16:08.424977Z",
          "iopub.status.busy": "2024-08-07T16:16:08.424704Z",
          "iopub.status.idle": "2024-08-07T16:16:08.488509Z",
          "shell.execute_reply": "2024-08-07T16:16:08.487581Z",
          "shell.execute_reply.started": "2024-08-07T16:16:08.424953Z"
        },
        "id": "t3ehOepji55a",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97d093fa-06fc-44d0-fa5a-18c6baba0188"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "28709\n"
          ]
        }
      ],
      "source": [
        "# Converting the lists of images and labels to NumPy arrays\n",
        "images = np.array(images)\n",
        "labels = np.array(labels)\n",
        "print(len(images))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XWRd7o4aDxIw"
      },
      "source": [
        "The dataset is divided into training, validation, and test sets using the `train_test_split` function from scikit-learn.\n",
        "\n",
        "- `X_train`, `y_train`: Images and labels for training.\n",
        "- `X_val`, `y_val`: Images and labels for validation.\n",
        "- `X_test`, `y_test`: Images and labels for testing.\n",
        "\n",
        "The data is split with 20% allocated to testing and 10% to validation, based on the original dataset. The `random_state` parameter is set to ensure that the split is reproducible."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-07T16:16:08.489870Z",
          "iopub.status.busy": "2024-08-07T16:16:08.489604Z",
          "iopub.status.idle": "2024-08-07T16:16:08.540233Z",
          "shell.execute_reply": "2024-08-07T16:16:08.539435Z",
          "shell.execute_reply.started": "2024-08-07T16:16:08.489847Z"
        },
        "id": "3RlIsHBIi9fQ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Splitting Dataset into training, validation, and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    images, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.1, random_state=42)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pkaWQ0_WD6iH"
      },
      "source": [
        "The `preprocessing` function is created to prepare the input images before passing them into the neural network model.\n",
        "\n",
        "- Normalize the pixel values by dividing them by 255.0, scaling the values to the range [0, 1].\n",
        "- Resize each image to a fixed size of 48x48 pixels using OpenCV's `resize` function.\n",
        "- Reshape the image array to fit the input format expected by the neural network model. The shape is `(batch_size, height, width, channels)`, where `batch_size` is `-1` to allow for a dynamic batch size, and `channels` is set to 1 for grayscale images.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-07T16:16:08.541823Z",
          "iopub.status.busy": "2024-08-07T16:16:08.541476Z",
          "iopub.status.idle": "2024-08-07T16:16:08.546654Z",
          "shell.execute_reply": "2024-08-07T16:16:08.545772Z",
          "shell.execute_reply.started": "2024-08-07T16:16:08.541792Z"
        },
        "id": "W-QcvS5EjA8z",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Preprocess the image\n",
        "def preprocessing(img):\n",
        "    img = img / 255.0\n",
        "    img = cv2.resize(img, (48, 48))\n",
        "    return img.reshape(-1, 48, 48, 1)  # Reshape to match input shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NHQ6x-hUEKrM"
      },
      "source": [
        "The code snippet applies the `preprocessing` function to each image in the training, validation, and test sets using the `map` function, and then transforms the resulting list of preprocessed images into NumPy arrays.\n",
        "\n",
        "- `map(preprocessing, X_train)`: Applies the `preprocessing` function to every image in `X_train`.\n",
        "- `list(map(...))`: Converts the map object into a list.\n",
        "- `np.array(...)`: Converts the list of preprocessed images into a NumPy array.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-07T16:16:08.548711Z",
          "iopub.status.busy": "2024-08-07T16:16:08.547964Z",
          "iopub.status.idle": "2024-08-07T16:16:09.277649Z",
          "shell.execute_reply": "2024-08-07T16:16:09.276772Z",
          "shell.execute_reply.started": "2024-08-07T16:16:08.548685Z"
        },
        "id": "xYlF0AWcFFVD",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Apply preprocessing to training, validation, and test sets\n",
        "X_train = np.array(list(map(preprocessing, X_train)))\n",
        "X_val = np.array(list(map(preprocessing, X_val)))\n",
        "X_test = np.array(list(map(preprocessing, X_test)))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhlFmsyUFMDy"
      },
      "source": [
        "The code reshapes the input data arrays to eliminate an unnecessary dimension. The neural network model expects input in the shape `(batch_size, height, width, channels)`, where `batch_size` denotes the number of samples per batch. The extra dimension is removed to match this expected format.\n",
        "\n",
        "- `reshape(-1, 48, 48, 1)`: Adjusts the input data arrays to a shape of `(batch_size, 48, 48, 1)`, where `-1` allows the batch size to be dynamically set based on the number of samples.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-07T16:16:09.279125Z",
          "iopub.status.busy": "2024-08-07T16:16:09.278829Z",
          "iopub.status.idle": "2024-08-07T16:16:09.283748Z",
          "shell.execute_reply": "2024-08-07T16:16:09.282880Z",
          "shell.execute_reply.started": "2024-08-07T16:16:09.279101Z"
        },
        "id": "Mfe4OENojGZM",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Reshape input data to remove unnecessary dimension\n",
        "X_train = X_train.reshape(-1, 48, 48, 1)\n",
        "X_val = X_val.reshape(-1, 48, 48, 1)\n",
        "X_test = X_test.reshape(-1, 48, 48, 1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AYvdbcs0Fb_F"
      },
      "source": [
        "The `ImageDataGenerator` object is set up with various data augmentation parameters to enhance the training images. Data augmentation is a method used to artificially expand the size of the training dataset by applying random transformations to the images, which helps improve the model's generalization and robustness.\n",
        "\n",
        "- `width_shift_range`: Randomly shifts the image horizontally by a fraction of its width.\n",
        "- `height_shift_range`: Randomly shifts the image vertically by a fraction of its height.\n",
        "- `zoom_range`: Randomly zooms in or out of the image.\n",
        "- `shear_range`: Applies random shear transformations to the image.\n",
        "- `rotation_range`: Rotates the image randomly within a specified angle range.\n",
        "\n",
        "After initializing the `ImageDataGenerator` object, the `fit()` method is called to compute the necessary statistics for data augmentation based on the training data.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-07T16:16:09.284950Z",
          "iopub.status.busy": "2024-08-07T16:16:09.284691Z",
          "iopub.status.idle": "2024-08-07T16:16:09.438314Z",
          "shell.execute_reply": "2024-08-07T16:16:09.437390Z",
          "shell.execute_reply.started": "2024-08-07T16:16:09.284928Z"
        },
        "id": "amlCUHiVjMGx",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Initialize ImageDataGenerator for data augmentation\n",
        "data_gen = ImageDataGenerator(\n",
        "    width_shift_range=0.1,\n",
        "    height_shift_range=0.1,\n",
        "    zoom_range=0.1,\n",
        "    shear_range=0.1,\n",
        "    rotation_range=10\n",
        ")\n",
        "\n",
        "# Compute necessary statistics for data augmentation\n",
        "data_gen.fit(X_train)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXPB--KSFqvw"
      },
      "source": [
        "The `LabelEncoder` object is initialized to convert class labels into numerical values. This conversion is essential because machine learning models generally require numerical input. The `fit()` method is then called on the `LabelEncoder` to train the encoder with the class labels, allowing it to map the labels to their corresponding numerical values.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 31,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-07T16:16:09.439762Z",
          "iopub.status.busy": "2024-08-07T16:16:09.439472Z",
          "iopub.status.idle": "2024-08-07T16:16:09.453108Z",
          "shell.execute_reply": "2024-08-07T16:16:09.452303Z",
          "shell.execute_reply.started": "2024-08-07T16:16:09.439738Z"
        },
        "id": "v-M6Td56jQnI",
        "outputId": "4a500816-41cd-4b6e-c8f1-fbab35ba4c2d",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LabelEncoder()"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LabelEncoder()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LabelEncoder</label><div class=\"sk-toggleable__content\"><pre>LabelEncoder()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ],
      "source": [
        "# Encode the class labels\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(labels)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ruMxfBiSF33b"
      },
      "source": [
        "The class labels for the training, validation, and test sets are encoded using the `transform()` method of the previously initialized `LabelEncoder` object. This method converts the class labels to their corresponding numerical values based on the mapping established during the fitting process.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-07T16:16:09.454321Z",
          "iopub.status.busy": "2024-08-07T16:16:09.454065Z",
          "iopub.status.idle": "2024-08-07T16:16:09.478420Z",
          "shell.execute_reply": "2024-08-07T16:16:09.477611Z",
          "shell.execute_reply.started": "2024-08-07T16:16:09.454300Z"
        },
        "id": "5-hx7_s8jTZb",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Encode the class labels for training, validation, and test sets\n",
        "y_train = label_encoder.transform(y_train)\n",
        "y_val = label_encoder.transform(y_val)\n",
        "y_test = label_encoder.transform(y_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7gVmDiaoGHLh"
      },
      "source": [
        "The variable `num_classes` is set to the number of unique classes in the dataset, which is obtained from the length of the `classes_` attribute of the `LabelEncoder` object.\n",
        "\n",
        "The `to_categorical()` function is then employed to convert the encoded class labels into one-hot encoded vectors. This conversion is crucial for multi-class classification tasks, where each class label is represented as a binary vector with a 1 in the position corresponding to the class index and 0s in all other positions.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-07T16:16:09.482771Z",
          "iopub.status.busy": "2024-08-07T16:16:09.482208Z",
          "iopub.status.idle": "2024-08-07T16:16:09.487873Z",
          "shell.execute_reply": "2024-08-07T16:16:09.487121Z",
          "shell.execute_reply.started": "2024-08-07T16:16:09.482747Z"
        },
        "id": "Pccke-XUjVeQ",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Get the number of classes\n",
        "num_classes = len(label_encoder.classes_)\n",
        "\n",
        "# Convert encoded class labels to one-hot encoded categorical arrays\n",
        "y_train_categorical = to_categorical(y_train, num_classes=num_classes)\n",
        "y_val_categorical = to_categorical(y_val, num_classes=num_classes)\n",
        "y_test_categorical = to_categorical(y_test, num_classes=num_classes)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nwv0iuDjGeHw"
      },
      "source": [
        "The `build_model` function defines the architecture of the convolutional neural network (CNN) designed for facial expression recognition.\n",
        "\n",
        "- **1st Layer**: Convolutional layer with 64 filters of size (5, 5), ReLU activation, and batch normalization. This layer is followed by MaxPooling and Dropout layers for regularization.\n",
        "\n",
        "- **2nd Layer**: Convolutional layer with 128 filters of size (3, 3), ReLU activation, and batch normalization, with MaxPooling and Dropout layers added for regularization.\n",
        "\n",
        "- **3rd Layer**: Convolutional layer with 512 filters of size (3, 3), ReLU activation, and batch normalization, accompanied by MaxPooling and Dropout layers for regularization.\n",
        "\n",
        "- **4th Layer**: Convolutional layer with 512 filters of size (3, 3), ReLU activation, and batch normalization, followed by MaxPooling and Dropout layers for regularization.\n",
        "\n",
        "- **Flatten Layer**: Flattens the output from the convolutional layers to prepare it for the fully connected layers.\n",
        "\n",
        "- **Fully Connected Layer 1**: Dense layer with 256 units and ReLU activation, including batch normalization and dropout for regularization.\n",
        "\n",
        "- **Fully Connected Layer 2**: Dense layer with 512 units and ReLU activation, with batch normalization and dropout applied for regularization.\n",
        "\n",
        "- **Output Layer**: Dense layer with softmax activation for multi-class classification, where the number of units corresponds to the number of classes in the dataset.\n",
        "\n",
        "- **Compilation**: The model is compiled using the Adam optimizer, categorical cross-entropy loss function, and accuracy metric.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-07T16:16:09.489134Z",
          "iopub.status.busy": "2024-08-07T16:16:09.488859Z",
          "iopub.status.idle": "2024-08-07T16:16:09.502583Z",
          "shell.execute_reply": "2024-08-07T16:16:09.501509Z",
          "shell.execute_reply.started": "2024-08-07T16:16:09.489109Z"
        },
        "id": "ebDumsoOjZJC",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Building Model\n",
        "def build_model():\n",
        "    model = Sequential()\n",
        "    # 1st Layer\n",
        "    model.add(Conv2D(64, (5, 5), strides=(1, 1), padding='same', activation='relu', input_shape=(48, 48, 1)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(2, 2))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # 2nd Layer\n",
        "    model.add(Conv2D(128, (3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(2, 2))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # 3rd layer\n",
        "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(2, 2))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # 4th layer\n",
        "    model.add(Conv2D(512, (3, 3), strides=(1, 1), padding='same', activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(MaxPooling2D(2, 2))\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # Flatten Layer\n",
        "    model.add(Flatten())\n",
        "\n",
        "    # Fully connected layer 1\n",
        "    model.add(Dense(256, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # Fully connected layer 2\n",
        "    model.add(Dense(512, activation='relu'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Dropout(0.3))\n",
        "\n",
        "    # Output layer\n",
        "    model.add(Dense(num_classes, activation='softmax'))\n",
        "\n",
        "    # Compiling the model\n",
        "    model.compile(optimizer=Adam(learning_rate=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3CiJpP4GvHS"
      },
      "source": [
        "The `summary()` method is invoked on the constructed model to provide an overview of its architecture. This summary includes details on the layers, their output shapes, and the number of trainable parameters.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-07T16:16:09.503778Z",
          "iopub.status.busy": "2024-08-07T16:16:09.503509Z",
          "iopub.status.idle": "2024-08-07T16:16:10.708421Z",
          "shell.execute_reply": "2024-08-07T16:16:10.707512Z",
          "shell.execute_reply.started": "2024-08-07T16:16:09.503756Z"
        },
        "id": "St5xjbyDjjGq",
        "outputId": "2017905b-1990-43cc-a312-c3b622bad8a8",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │           \u001b[38;5;34m1,664\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m48\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m256\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m24\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │         \u001b[38;5;34m590,336\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m512\u001b[0m)         │           \u001b[38;5;34m2,048\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │       \u001b[38;5;34m2,359,808\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_3                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │           \u001b[38;5;34m2,048\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m512\u001b[0m)           │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4608\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │       \u001b[38;5;34m1,179,904\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_4                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │           \u001b[38;5;34m1,024\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │         \u001b[38;5;34m131,584\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_5                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │           \u001b[38;5;34m2,048\u001b[0m │\n",
              "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)                   │           \u001b[38;5;34m3,591\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,664</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │         <span style=\"color: #00af00; text-decoration-color: #00af00\">590,336</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)         │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │       <span style=\"color: #00af00; text-decoration-color: #00af00\">2,359,808</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_3                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)           │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4608</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │       <span style=\"color: #00af00; text-decoration-color: #00af00\">1,179,904</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_4                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">131,584</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ batch_normalization_5                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │           <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> │\n",
              "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)                   │           <span style=\"color: #00af00; text-decoration-color: #00af00\">3,591</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m4,348,679\u001b[0m (16.59 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,348,679</span> (16.59 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,344,711\u001b[0m (16.57 MB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,344,711</span> (16.57 MB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m3,968\u001b[0m (15.50 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">3,968</span> (15.50 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ],
      "source": [
        "# Build the model\n",
        "model = build_model()\n",
        "\n",
        "# Print model summary\n",
        "print(model.summary())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wLTQrJYkG_Tg"
      },
      "source": [
        "The `ModelCheckpoint` callback is set up to save the model weights during training. It tracks the validation accuracy (`val_acc`) and saves only the best model, as determined by the highest validation accuracy, to the specified file `\"model.h5\"`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-07T16:16:10.710061Z",
          "iopub.status.busy": "2024-08-07T16:16:10.709712Z",
          "iopub.status.idle": "2024-08-07T16:16:10.715573Z",
          "shell.execute_reply": "2024-08-07T16:16:10.714303Z",
          "shell.execute_reply.started": "2024-08-07T16:16:10.710030Z"
        },
        "id": "M-smbpQKkVV7",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Initialize ModelCheckpoint callback\n",
        "# checkpoint = ModelCheckpoint(\"model.h5\", monitor=\"val_acc\", verbose=1, save_best_only=True)\n",
        "# Initialize ModelCheckpoint callback\n",
        "checkpoint = ModelCheckpoint(\"model.keras\", monitor=\"val_acc\", verbose=1, save_best_only=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oBiZw1EpHkFv"
      },
      "source": [
        "The `EarlyStopping` callback is configured to monitor the validation loss (`val_loss`). It halts the training process if the validation loss does not improve for a specified number of epochs (`patience`). This early stopping helps prevent overfitting, and the weights of the best-performing model are restored (`restore_best_weights=True`).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-07T16:16:10.717020Z",
          "iopub.status.busy": "2024-08-07T16:16:10.716716Z",
          "iopub.status.idle": "2024-08-07T16:16:10.726181Z",
          "shell.execute_reply": "2024-08-07T16:16:10.725363Z",
          "shell.execute_reply.started": "2024-08-07T16:16:10.716974Z"
        },
        "id": "zuArFO2GkbKM",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Initialize EarlyStopping callback\n",
        "early_stopping = EarlyStopping(\n",
        "    monitor='val_loss',\n",
        "    min_delta=0,\n",
        "    patience=3,\n",
        "    verbose=1,\n",
        "    restore_best_weights=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTAehL6DHvym"
      },
      "source": [
        "The `ReduceLROnPlateau` callback is configured to adjust the learning rate dynamically during training based on the validation loss (`val_loss`). If the validation loss does not show improvement for a defined number of epochs (`patience`), the learning rate is reduced by a specified factor (`factor`). This adjustment helps enhance the training process and prevents the model from getting stuck in local minima.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-07T16:16:10.729467Z",
          "iopub.status.busy": "2024-08-07T16:16:10.727270Z",
          "iopub.status.idle": "2024-08-07T16:16:10.734941Z",
          "shell.execute_reply": "2024-08-07T16:16:10.734215Z",
          "shell.execute_reply.started": "2024-08-07T16:16:10.729442Z"
        },
        "id": "FcWqpIDfkdkh",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Initialize ReduceLROnPlateau callback\n",
        "reduce_learningrate = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    factor=0.2,\n",
        "    patience=3,\n",
        "    verbose=1,\n",
        "    min_delta=0.0001\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJwx_MScH6Vh"
      },
      "source": [
        "The `callbacks_list` is a list that includes the callbacks to be applied during model training. It consists of the `EarlyStopping`, `ModelCheckpoint`, and `ReduceLROnPlateau` callbacks. These callbacks are used to monitor the validation loss, save the best model, and adjust the learning rate, respectively.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-07T16:16:10.736540Z",
          "iopub.status.busy": "2024-08-07T16:16:10.736030Z",
          "iopub.status.idle": "2024-08-07T16:16:10.747465Z",
          "shell.execute_reply": "2024-08-07T16:16:10.746695Z",
          "shell.execute_reply.started": "2024-08-07T16:16:10.736501Z"
        },
        "id": "hkFIZipIkgA_",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# List of callbacks\n",
        "callbacks_list = [early_stopping, checkpoint, reduce_learningrate]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "22-FfpcpIJX8"
      },
      "source": [
        "The `compile()` method is invoked on the model to set up the training process. It defines the loss function, optimizer, and evaluation metrics to be used during training.\n",
        "\n",
        "- **Loss Function**: Categorical cross-entropy is selected for handling multi-class classification tasks.\n",
        "- **Optimizer**: The Adam optimizer is used with a learning rate of 0.001.\n",
        "- **Metrics**: Accuracy is chosen as the evaluation metric to track the model's performance throughout training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-07T16:16:10.748832Z",
          "iopub.status.busy": "2024-08-07T16:16:10.748541Z",
          "iopub.status.idle": "2024-08-07T16:16:10.759911Z",
          "shell.execute_reply": "2024-08-07T16:16:10.759006Z",
          "shell.execute_reply.started": "2024-08-07T16:16:10.748809Z"
        },
        "id": "_DgH_tueki6T",
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "model.compile(\n",
        "    loss='categorical_crossentropy',\n",
        "    optimizer=Adam(learning_rate=0.001),\n",
        "    metrics=['accuracy']\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WacGYPD5IlBk"
      },
      "source": [
        "The `fit()` method is called on the model to train it using the training data. It accepts the following parameters:\n",
        "\n",
        "- `data_gen.flow(X_train, y_train_categorical, batch_size=128)`: A data generator that produces batches of augmented training data, with on-the-fly data augmentation provided by the `ImageDataGenerator` object defined earlier.\n",
        "- `validation_data=(X_val, y_val_categorical)`: Validation data used to assess the model's performance after each epoch.\n",
        "- `epochs=50`: The total number of epochs for training the model.\n",
        "- `verbose=1`: Determines the verbosity level, with `1` enabling progress bars during training.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-07T16:16:10.761715Z",
          "iopub.status.busy": "2024-08-07T16:16:10.761421Z",
          "iopub.status.idle": "2024-08-07T16:23:48.266327Z",
          "shell.execute_reply": "2024-08-07T16:23:48.265487Z",
          "shell.execute_reply.started": "2024-08-07T16:16:10.761690Z"
        },
        "id": "5kzrbdyx_UqG",
        "trusted": true,
        "outputId": "ef949386-84a7-4173-dd62-17d713260fc6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
            "  self._warn_if_super_not_called()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 153ms/step - accuracy: 0.1933 - loss: 2.3862 - val_accuracy: 0.2625 - val_loss: 2.9809\n",
            "Epoch 2/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 68ms/step - accuracy: 0.2726 - loss: 1.9118 - val_accuracy: 0.1641 - val_loss: 3.2641\n",
            "Epoch 3/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 73ms/step - accuracy: 0.3357 - loss: 1.7342 - val_accuracy: 0.2238 - val_loss: 3.6053\n",
            "Epoch 4/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 74ms/step - accuracy: 0.3829 - loss: 1.6068 - val_accuracy: 0.3304 - val_loss: 2.4088\n",
            "Epoch 5/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 73ms/step - accuracy: 0.4245 - loss: 1.5173 - val_accuracy: 0.4580 - val_loss: 1.4100\n",
            "Epoch 6/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 71ms/step - accuracy: 0.4447 - loss: 1.4381 - val_accuracy: 0.4758 - val_loss: 1.3229\n",
            "Epoch 7/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 93ms/step - accuracy: 0.4724 - loss: 1.3734 - val_accuracy: 0.5072 - val_loss: 1.2675\n",
            "Epoch 8/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 85ms/step - accuracy: 0.4964 - loss: 1.3213 - val_accuracy: 0.5159 - val_loss: 1.2614\n",
            "Epoch 9/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 74ms/step - accuracy: 0.5087 - loss: 1.2945 - val_accuracy: 0.5263 - val_loss: 1.2136\n",
            "Epoch 10/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 88ms/step - accuracy: 0.5186 - loss: 1.2684 - val_accuracy: 0.5320 - val_loss: 1.2553\n",
            "Epoch 11/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 99ms/step - accuracy: 0.5303 - loss: 1.2419 - val_accuracy: 0.5281 - val_loss: 1.2126\n",
            "Epoch 12/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 93ms/step - accuracy: 0.5458 - loss: 1.2081 - val_accuracy: 0.5572 - val_loss: 1.1524\n",
            "Epoch 13/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 77ms/step - accuracy: 0.5472 - loss: 1.1900 - val_accuracy: 0.5316 - val_loss: 1.2101\n",
            "Epoch 14/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 87ms/step - accuracy: 0.5547 - loss: 1.1690 - val_accuracy: 0.5686 - val_loss: 1.1248\n",
            "Epoch 15/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 90ms/step - accuracy: 0.5612 - loss: 1.1576 - val_accuracy: 0.5394 - val_loss: 1.1918\n",
            "Epoch 16/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 74ms/step - accuracy: 0.5687 - loss: 1.1416 - val_accuracy: 0.6125 - val_loss: 1.0421\n",
            "Epoch 17/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 84ms/step - accuracy: 0.5809 - loss: 1.1093 - val_accuracy: 0.5973 - val_loss: 1.0943\n",
            "Epoch 18/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 93ms/step - accuracy: 0.5808 - loss: 1.1014 - val_accuracy: 0.6012 - val_loss: 1.0491\n",
            "Epoch 19/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 72ms/step - accuracy: 0.5946 - loss: 1.0752 - val_accuracy: 0.6056 - val_loss: 1.0457\n",
            "Epoch 20/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 73ms/step - accuracy: 0.6014 - loss: 1.0573 - val_accuracy: 0.6030 - val_loss: 1.0628\n",
            "Epoch 21/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 74ms/step - accuracy: 0.6025 - loss: 1.0549 - val_accuracy: 0.6051 - val_loss: 1.0381\n",
            "Epoch 22/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 74ms/step - accuracy: 0.6064 - loss: 1.0427 - val_accuracy: 0.6186 - val_loss: 0.9963\n",
            "Epoch 23/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 73ms/step - accuracy: 0.6069 - loss: 1.0450 - val_accuracy: 0.6082 - val_loss: 1.0317\n",
            "Epoch 24/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 73ms/step - accuracy: 0.6158 - loss: 1.0104 - val_accuracy: 0.6313 - val_loss: 0.9769\n",
            "Epoch 25/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 79ms/step - accuracy: 0.6197 - loss: 1.0072 - val_accuracy: 0.6012 - val_loss: 1.0423\n",
            "Epoch 26/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 74ms/step - accuracy: 0.6290 - loss: 0.9908 - val_accuracy: 0.6199 - val_loss: 0.9931\n",
            "Epoch 27/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 74ms/step - accuracy: 0.6420 - loss: 0.9739 - val_accuracy: 0.6295 - val_loss: 0.9949\n",
            "Epoch 28/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 74ms/step - accuracy: 0.6344 - loss: 0.9654 - val_accuracy: 0.6091 - val_loss: 1.0325\n",
            "Epoch 29/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 75ms/step - accuracy: 0.6375 - loss: 0.9637 - val_accuracy: 0.6221 - val_loss: 1.0143\n",
            "Epoch 30/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 74ms/step - accuracy: 0.6315 - loss: 0.9650 - val_accuracy: 0.6143 - val_loss: 1.0228\n",
            "Epoch 31/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 74ms/step - accuracy: 0.6372 - loss: 0.9575 - val_accuracy: 0.6382 - val_loss: 0.9641\n",
            "Epoch 32/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 70ms/step - accuracy: 0.6500 - loss: 0.9323 - val_accuracy: 0.6360 - val_loss: 0.9819\n",
            "Epoch 33/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 74ms/step - accuracy: 0.6521 - loss: 0.9222 - val_accuracy: 0.6304 - val_loss: 0.9993\n",
            "Epoch 34/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 74ms/step - accuracy: 0.6519 - loss: 0.9213 - val_accuracy: 0.6165 - val_loss: 1.0548\n",
            "Epoch 35/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 75ms/step - accuracy: 0.6602 - loss: 0.9022 - val_accuracy: 0.6017 - val_loss: 1.0689\n",
            "Epoch 36/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 71ms/step - accuracy: 0.6643 - loss: 0.8837 - val_accuracy: 0.6487 - val_loss: 0.9530\n",
            "Epoch 37/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 72ms/step - accuracy: 0.6596 - loss: 0.8852 - val_accuracy: 0.6156 - val_loss: 1.0546\n",
            "Epoch 38/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 75ms/step - accuracy: 0.6739 - loss: 0.8677 - val_accuracy: 0.6404 - val_loss: 0.9785\n",
            "Epoch 39/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 74ms/step - accuracy: 0.6797 - loss: 0.8640 - val_accuracy: 0.6378 - val_loss: 0.9957\n",
            "Epoch 40/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 74ms/step - accuracy: 0.6688 - loss: 0.8727 - val_accuracy: 0.6417 - val_loss: 0.9927\n",
            "Epoch 41/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 72ms/step - accuracy: 0.6792 - loss: 0.8496 - val_accuracy: 0.6330 - val_loss: 1.0092\n",
            "Epoch 42/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 74ms/step - accuracy: 0.6854 - loss: 0.8422 - val_accuracy: 0.6365 - val_loss: 1.0200\n",
            "Epoch 43/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 75ms/step - accuracy: 0.6957 - loss: 0.8328 - val_accuracy: 0.6478 - val_loss: 0.9587\n",
            "Epoch 44/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 75ms/step - accuracy: 0.6871 - loss: 0.8219 - val_accuracy: 0.6326 - val_loss: 1.0105\n",
            "Epoch 45/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 76ms/step - accuracy: 0.7011 - loss: 0.8081 - val_accuracy: 0.6582 - val_loss: 0.9462\n",
            "Epoch 46/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 74ms/step - accuracy: 0.7068 - loss: 0.7970 - val_accuracy: 0.6665 - val_loss: 0.9555\n",
            "Epoch 47/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 69ms/step - accuracy: 0.7033 - loss: 0.7897 - val_accuracy: 0.6543 - val_loss: 0.9954\n",
            "Epoch 48/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 74ms/step - accuracy: 0.7043 - loss: 0.7825 - val_accuracy: 0.6469 - val_loss: 1.0128\n",
            "Epoch 49/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 74ms/step - accuracy: 0.7162 - loss: 0.7734 - val_accuracy: 0.6543 - val_loss: 0.9934\n",
            "Epoch 50/50\n",
            "\u001b[1m162/162\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 74ms/step - accuracy: 0.7159 - loss: 0.7666 - val_accuracy: 0.6704 - val_loss: 0.9455\n"
          ]
        }
      ],
      "source": [
        "# Training the model\n",
        "history = model.fit(\n",
        "    data_gen.flow(X_train, y_train_categorical, batch_size=128),\n",
        "    validation_data=(X_val, y_val_categorical),\n",
        "    epochs=50,\n",
        "    verbose=1\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CUBFBK2qIxj4"
      },
      "source": [
        "The trained model is saved to a file named `'modelv1.h5'` using the `save()` method. This file includes the model's architecture, weights, and training configuration, enabling you to reload the model later for inference or additional training."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-07T16:24:04.882133Z",
          "iopub.status.busy": "2024-08-07T16:24:04.881470Z",
          "iopub.status.idle": "2024-08-07T16:24:05.206475Z",
          "shell.execute_reply": "2024-08-07T16:24:05.205665Z",
          "shell.execute_reply.started": "2024-08-07T16:24:04.882093Z"
        },
        "trusted": true,
        "id": "2WT1_HPvwMRN"
      },
      "outputs": [],
      "source": [
        "# Save the model with .keras extension\n",
        "model.save(\"Custom_CNN_model.keras\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-07T16:24:09.332230Z",
          "iopub.status.busy": "2024-08-07T16:24:09.331337Z",
          "iopub.status.idle": "2024-08-07T16:24:09.518604Z",
          "shell.execute_reply": "2024-08-07T16:24:09.517591Z",
          "shell.execute_reply.started": "2024-08-07T16:24:09.332194Z"
        },
        "id": "uF0F95fykoDV",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4220b57-e876-402c-9e1b-481275af6f98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        }
      ],
      "source": [
        "# Saving the model with .h5 extension\n",
        "model.save('Custom_CNN_model.h5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Es_-GrjvJRKq"
      },
      "source": [
        "The code snippet plots the model's accuracy over epochs for both training and validation. This visualization helps track the model's performance over time and assists in identifying issues such as overfitting or underfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "execution": {
          "iopub.execute_input": "2024-08-07T16:24:13.131811Z",
          "iopub.status.busy": "2024-08-07T16:24:13.131471Z",
          "iopub.status.idle": "2024-08-07T16:24:13.415255Z",
          "shell.execute_reply": "2024-08-07T16:24:13.414305Z",
          "shell.execute_reply.started": "2024-08-07T16:24:13.131784Z"
        },
        "id": "SxmRSt_sxDve",
        "trusted": true,
        "outputId": "1589af46-3243-4a1c-9c59-ed229dcaa6e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjcAAAHHCAYAAABDUnkqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB8IklEQVR4nO3dd3gUVdvH8e9uOpCEmkoLRSBUqYJiAwXRgAqCFUREQSyI+ij6KGADy4NY8bUgKiiKFRtKURAEURAEAyhIJyHUJARS2J33j0kWNtndbJJNNoTf57pybTJzZvbsgObmnPvcx2IYhoGIiIhIFWH1dwdEREREfEnBjYiIiFQpCm5ERESkSlFwIyIiIlWKghsRERGpUhTciIiISJWi4EZERESqFAU3IiIiUqUouBEREZEqRcGNiPiMxWJh4sSJJb5u+/btWCwWZs6c6fM+iciZR8GNSBUzc+ZMLBYLFouFZcuWFTlvGAYNGjTAYrFwxRVX+KGHvvHtt99isViIi4vDbrf7uzsiUokouBGpokJDQ/nggw+KHF+yZAm7d+8mJCTED73yndmzZ9O4cWNSUlJYvHixv7sjIpWIghuRKqpfv37MnTuXEydOOB3/4IMP6NSpEzExMX7qWdllZWXx5ZdfMm7cOM4++2xmz57t7y65lZWV5e8uiJxxFNyIVFHXXXcdBw8eZMGCBY5jubm5fPLJJ1x//fUur8nKyuK+++6jQYMGhISE0KJFC55//nkMw3Bql5OTw7333ku9evUIDw+nf//+7N692+U99+zZwy233EJ0dDQhISG0bt2aGTNmlOmzff755xw/fpxrrrmGa6+9ls8++4zs7Owi7bKzs5k4cSJnnXUWoaGhxMbGcvXVV7N161ZHG7vdzosvvkjbtm0JDQ2lXr169O3bl99//x3wnA9UOMdo4sSJWCwWkpOTuf7666lVqxbnnXceAH/++Sc333wzTZo0ITQ0lJiYGG655RYOHjzo8pmNGDGCuLg4QkJCSEhIYPTo0eTm5vLvv/9isVh44YUXilz3yy+/YLFY+PDDD0v6SEWqlEB/d0BEykfjxo3p3r07H374IZdddhkA3333Henp6Vx77bW89NJLTu0Nw6B///78+OOPjBgxgg4dOvD999/zwAMPsGfPHqdfprfeeiuzZs3i+uuvp0ePHixevJjLL7+8SB/27dvHOeecg8Vi4c4776RevXp89913jBgxgoyMDMaOHVuqzzZ79mwuuugiYmJiuPbaa3nooYf46quvuOaaaxxtbDYbV1xxBYsWLeLaa6/lnnvuITMzkwULFrBhwwaaNm0KwIgRI5g5cyaXXXYZt956KydOnODnn39m5cqVdO7cuVT9u+aaa2jevDlPP/20IzBcsGAB//77L8OHDycmJoa//vqLN954g7/++ouVK1disVgA2Lt3L127duXIkSPcdttttGzZkj179vDJJ59w7NgxmjRpwrnnnsvs2bO59957izyX8PBwBgwYUKp+i1QZhohUKe+8844BGL/99pvxyiuvGOHh4caxY8cMwzCMa665xrjooosMwzCMRo0aGZdffrnjui+++MIAjCeffNLpfoMGDTIsFouxZcsWwzAMY+3atQZg3HHHHU7trr/+egMwJkyY4Dg2YsQIIzY21jhw4IBT22uvvdaIjIx09Gvbtm0GYLzzzjvFfr59+/YZgYGBxptvvuk41qNHD2PAgAFO7WbMmGEAxtSpU4vcw263G4ZhGIsXLzYA4+6773bbxlPfCn/eCRMmGIBx3XXXFWlb8FlP9eGHHxqAsXTpUsexoUOHGlar1fjtt9/c9un//u//DMDYuHGj41xubq5Rt25dY9iwYUWuEznTaFpKpAobPHgwx48f5+uvvyYzM5Ovv/7a7ZTUt99+S0BAAHfffbfT8fvuuw/DMPjuu+8c7YAi7QqPwhiGwaeffkpSUhKGYXDgwAHHV58+fUhPT2fNmjUl/kxz5szBarUycOBAx7HrrruO7777jsOHDzuOffrpp9StW5e77rqryD0KRkk+/fRTLBYLEyZMcNumNEaNGlXkWFhYmOP77OxsDhw4wDnnnAPgeA52u50vvviCpKQkl6NGBX0aPHgwoaGhTrlG33//PQcOHODGG28sdb9FqgoFNyJVWL169ejduzcffPABn332GTabjUGDBrlsu2PHDuLi4ggPD3c63qpVK8f5gler1eqY1inQokULp5/379/PkSNHeOONN6hXr57T1/DhwwFIS0sr8WeaNWsWXbt25eDBg2zZsoUtW7Zw9tlnk5uby9y5cx3ttm7dSosWLQgMdD/7vnXrVuLi4qhdu3aJ++FJQkJCkWOHDh3innvuITo6mrCwMOrVq+dol56eDpjPLCMjgzZt2ni8f82aNUlKSnJaDTd79mzi4+O5+OKLffhJRE5PyrkRqeKuv/56Ro4cSWpqKpdddhk1a9askPctqD1z4403MmzYMJdt2rVrV6J7/vPPP/z2228ANG/evMj52bNnc9ttt5Wwp565G8Gx2Wxurzl1lKbA4MGD+eWXX3jggQfo0KEDNWrUwG6307dv31LV6Rk6dChz587ll19+oW3btsybN4877rgDq1X/ZhVRcCNSxV111VXcfvvtrFy5ko8++shtu0aNGrFw4UIyMzOdRm82bdrkOF/warfbHSMjBTZv3ux0v4KVVDabjd69e/vks8yePZugoCDef/99AgICnM4tW7aMl156iZ07d9KwYUOaNm3Kr7/+Sl5eHkFBQS7v17RpU77//nsOHTrkdvSmVq1aABw5csTpeMFIljcOHz7MokWLmDRpEo899pjj+D///OPUrl69ekRERLBhw4Zi79m3b1/q1avH7Nmz6datG8eOHeOmm27yuk8iVZlCfJEqrkaNGkyfPp2JEyeSlJTktl2/fv2w2Wy88sorTsdfeOEFLBaLY8VVwWvh1VbTpk1z+jkgIICBAwfy6aefuvxlvX///hJ/ltmzZ9OzZ0+GDBnCoEGDnL4eeOABAMcy6IEDB3LgwIEinwdwrGAaOHAghmEwadIkt20iIiKoW7cuS5cudTr/2muved3vgkDMKLSkvvAzs1qtXHnllXz11VeOpeiu+gQQGBjIddddx8cff8zMmTNp27ZtiUfCRKoqjdyInAHcTQudKikpiYsuuohHHnmE7du30759e3744Qe+/PJLxo4d68ix6dChA9dddx2vvfYa6enp9OjRg0WLFrFly5Yi95wyZQo//vgj3bp1Y+TIkSQmJnLo0CHWrFnDwoULOXTokNef4ddff2XLli3ceeedLs/Hx8fTsWNHZs+ezYMPPsjQoUN57733GDduHKtWraJnz55kZWWxcOFC7rjjDgYMGMBFF13ETTfdxEsvvcQ///zjmCL6+eefueiiixzvdeuttzJlyhRuvfVWOnfuzNKlS/n777+97ntERATnn38+zz77LHl5ecTHx/PDDz+wbdu2Im2ffvppfvjhBy644AJuu+02WrVqRUpKCnPnzmXZsmVO04pDhw7lpZde4scff+SZZ57xuj8iVZ7/FmqJSHk4dSm4J4WXghuGYWRmZhr33nuvERcXZwQFBRnNmzc3nnvuOccS5ALHjx837r77bqNOnTpG9erVjaSkJGPXrl1FlkYbhrl0e8yYMUaDBg2MoKAgIyYmxujVq5fxxhtvONp4sxT8rrvuMgBj69atbttMnDjRAIx169YZhmEuv37kkUeMhIQEx3sPGjTI6R4nTpwwnnvuOaNly5ZGcHCwUa9ePeOyyy4zVq9e7Whz7NgxY8SIEUZkZKQRHh5uDB482EhLS3O7FHz//v1F+rZ7927jqquuMmrWrGlERkYa11xzjbF3716Xz2zHjh3G0KFDjXr16hkhISFGkyZNjDFjxhg5OTlF7tu6dWvDarUau3fvdvtcRM40FsMoNE4qIiKnjbPPPpvatWuzaNEif3dFpNJQzo2IyGnq999/Z+3atQwdOtTfXRGpVDRyIyJymtmwYQOrV6/mf//7HwcOHODff/8lNDTU390SqTQ0ciMicpr55JNPGD58OHl5eXz44YcKbEQK0ciNiIiIVCkauREREZEqRcGNiIiIVClnXBE/u93O3r17CQ8PL9OuvyIiIlJxDMMgMzOTuLi4YvdQO+OCm71799KgQQN/d0NERERKYdeuXdSvX99jmzMuuCnYEHDXrl1ERET4uTciIiLijYyMDBo0aOC0sa87Z1xwUzAVFRERoeBGRETkNONNSokSikVERKRKUXAjIiIiVYqCGxEREalSzricG2/ZbDby8vL83Q2pQoKCgggICPB3N0REqjwFN4UYhkFqaipHjhzxd1ekCqpZsyYxMTGqsSQiUo4U3BRSENhERUVRrVo1/RISnzAMg2PHjpGWlgZAbGysn3skIlJ1Kbg5hc1mcwQ2derU8Xd3pIoJCwsDIC0tjaioKE1RiYiUEyUUn6Igx6ZatWp+7olUVQV/t5TPJSJSfhTcuKCpKCkv+rslIlL+NC0lIiIixbLZDVZtO0RaZjZR4aF0TahNgNVS4jYVQcGNFNG4cWPGjh3L2LFj/d0VERGpBOZvSGHSV8mkpGc7jsVGhjIhKZG+bWK9blNRFNyUk4qOXi+88EI6dOjAtGnTynyv3377jerVq5e9UyIictqbvyGF0bPWYBQ6npqezehZa5h+Y0eAYttUZICj4KYcVKbotYBhGNhsNgIDi/8jr1evXgX0yH9yc3MJDg72dzdERCo9m91g0lfJRYIWwHHssS83ABa3bSzApK+SuSQxpsKmqJRQ7GMFEe6pgQ2cjF7nb0jx+XvefPPNLFmyhBdffBGLxYLFYmHmzJlYLBa+++47OnXqREhICMuWLWPr1q0MGDCA6OhoatSoQZcuXVi4cKHT/Ro3buw0AmSxWHjrrbe46qqrqFatGs2bN2fevHle9c1mszFixAgSEhIICwujRYsWvPjii0XazZgxg9atWxMSEkJsbCx33nmn49yRI0e4/fbbiY6OJjQ0lDZt2vD1118DMHHiRDp06OB0r2nTptG4cWOn53PllVfy1FNPERcXR4sWLQB4//336dy5M+Hh4cTExHD99dc76tAU+Ouvv7jiiiuIiIggPDycnj17snXrVpYuXUpQUBCpqalO7ceOHUvPnj29ejYiIpXdqm2Hivw+KywtM5e0zBy35w0gJT2bVdsO+bh37im4KYZhGBzLPeHVV2Z2HhPm/eUxwp04L5nM7Dyv7mcYru5U1Isvvkj37t0ZOXIkKSkppKSk0KBBAwAeeughpkyZwsaNG2nXrh1Hjx6lX79+LFq0iD/++IO+ffuSlJTEzp07Pb7HpEmTGDx4MH/++Sf9+vXjhhtu4NCh4v+i2u126tevz9y5c0lOTuaxxx7j4Ycf5uOPP3a0mT59OmPGjOG2225j/fr1zJs3j2bNmjmuv+yyy1i+fDmzZs0iOTmZKVOmlLhGzKJFi9i8eTMLFixwBEZ5eXk88cQTrFu3ji+++ILt27dz8803O67Zs2cP559/PiEhISxevJjVq1dzyy23cOLECc4//3yaNGnC+++/72ifl5fH7NmzueWWW0rUNxERf7LZDVZsPciXa/ewYutBbPaTv3t2HMry2fukZXoOknxJ01LFOJ5nI/Gx731yLwNIzcim7cQfvGqf/HgfqgUX/0cUGRlJcHAw1apVIyYmBoBNmzYB8Pjjj3PJJZc42tauXZv27ds7fn7iiSf4/PPPmTdvntNoSWE333wz1113HQBPP/00L730EqtWraJv374e+xYUFMSkSZMcPyckJLBixQo+/vhjBg8eDMCTTz7Jfffdxz333ONo16VLFwAWLlzIqlWr2LhxI2eddRYATZo0KfaZFFa9enXeeustp+moU4OQJk2a8NJLL9GlSxeOHj1KjRo1ePXVV4mMjGTOnDkEBQUBOPoAMGLECN555x0eeOABAL766iuys7Mdn0tEpDz5IrfTXRrFo5cnkpGdx9PfbvRZf6PCQ312r+IouKniOnfu7PTz0aNHmThxIt988w0pKSmcOHGC48ePFzty065dO8f31atXJyIiosgUjjuvvvoqM2bMYOfOnRw/fpzc3FzHVFJaWhp79+6lV69eLq9du3Yt9evXdwoqSqNt27ZF8mxWr17NxIkTWbduHYcPH8ZutwOwc+dOEhMTWbt2LT179nQENoXdfPPN/Pe//2XlypWcc845zJw5k8GDBysZW0TKnbe5nZ4CIHeJwinp2dzxwRrHzwFWi9NozqksQHRECGBhX0a2y5kLCxATab53RakUwc2rr77Kc889R2pqKu3bt+fll1+ma9euLtteeOGFLFmypMjxfv368c033/i8b2FBASQ/3sertqu2HeLmd34rtt3M4V28+kMOCyp7ef7Cv2jvv/9+FixYwPPPP0+zZs0ICwtj0KBB5ObmerxP4V/wFovFEQx4MmfOHO6//37+97//0b17d8LDw3nuuef49ddfgZNbErhT3Hmr1Vpk+s5V9d/CzyErK4s+ffrQp08fZs+eTb169di5cyd9+vRxPIvi3jsqKoqkpCTeeecdEhIS+O677/jpp588XiMiUlberF7q2ybWYwB0SWKM20ThAhbg4ctbERsZyl0f/AHg1L5gjGhi/9aAuVrK4qbNhKTECq134/fg5qOPPmLcuHG8/vrrdOvWjWnTptGnTx82b95MVFRUkfafffaZ0y/igwcP0r59e6655ppy6Z/FYvFqagigZ/N6xEaGkpruOXrt2byez/+Qg4ODsdlsxbZbvnw5N998M1dddRVgjuRs377dp30p/H49evTgjjvucBzbunWr4/vw8HAaN27MokWLuOiii4pc365dO3bv3s3ff//tcvSmXr16pKamYhiGo/rv2rVri+3Xpk2bOHjwIFOmTHHkJ/3+++9F3vvdd98lLy/P7ejNrbfeynXXXUf9+vVp2rQp5557brHvLSJSWsWtXipYmWS3w5gP3AdAw89tXGyisAG0iYuke9M6BFotRQKlmEIjRdNv7Fhsm4ri9+Bm6tSpjBw5kuHDhwPw+uuv88033zBjxgweeuihIu1r13Ye8ZgzZw7VqlUrt+CmJAKsFiYkJfolem3cuDG//vor27dvp0aNGm5HVZo3b85nn31GUlISFouFRx991KsRmNJq3rw57733Ht9//z0JCQm8//77/PbbbyQkJDjaTJw4kVGjRhEVFcVll11GZmYmy5cv56677uKCCy7g/PPPZ+DAgUydOpVmzZqxadMmLBYLffv25cILL2T//v08++yzDBo0iPnz5/Pdd98RERHhsV8NGzYkODiYl19+mVGjRrFhwwaeeOIJpzZ33nknL7/8Mtdeey3jx48nMjKSlStX0rVrV8eKqz59+hAREcGTTz7J448/7vsHKCJyiuJWLxWsTLr347UeF7fMWL7dq/crSALu2yaWSxJjPOb4eNOmovh1tVRubi6rV6+md+/ejmNWq5XevXuzYsUKr+7x9ttvc+2117rNc8jJySEjI8Ppqzz1bRPL9Bs7EhPpnDgVExlarkWM7r//fgICAkhMTHRMsbgydepUatWqRY8ePUhKSqJPnz507NixXPoEcPvtt3P11VczZMgQunXrxsGDB51GcQCGDRvGtGnTeO2112jdujVXXHEF//zzj+P8p59+SpcuXbjuuutITEzkP//5j2OUqlWrVrz22mu8+uqrtG/fnlWrVnH//fcX26969eoxc+ZM5s6dS2JiIlOmTOH55593alOnTh0WL17M0aNHueCCC+jUqRNvvvmm0yiO1Wrl5ptvxmazMXTo0LI8KhGRYnm74ijnhG/+0XpqEnCA1UL3pnUY0CGe7k3ruAxavGlTESyGt+uNy8HevXuJj4/nl19+oXv37o7j//nPf1iyZIkjL8OdVatW0a1bN3799Ve3OToTJ050Wq1TID09vci/7rOzs9m2bRsJCQmEhpYtq7uy7K8h5W/EiBHs37/fq9o/vvw7JiJVl7vfIa/++A/Pff+3T96jZlgQ6cfzPKZRLHvw4krzuysjI4PIyEiXv78L8/u0VFm8/fbbtG3b1m1gAzB+/HjGjRvn+DkjI8ORY1GeCqJXqbrS09NZv349H3zwgddFDUVEiuMqEbheeAixESH8ucfz7IMFqFU9iENZRRdWFDb83ASmLfy70iQB+5Jfp6Xq1q1LQEAA+/btczq+b98+R70Wd7KyspgzZw4jRozw2C4kJISIiAinL/GdUaNGUaNGDZdfo0aN8nf3ytWAAQO49NJLGTVqlFMtIRGR0nJX5X5/Zg5/7snAaoFLE6OxcDIIKVDw85MD2hAbGVrk/KntYiNDufPiZn5Jo6gIfh25CQ4OplOnTixatIgrr7wSMCvSLlq0yGNBOYC5c+eSk5PDjTfeWAE9FXcef/xxtzkuVT2Q1LJvEfElTyuhCtSpEcL0GzuxIDnV48okq9Xi1eKWypQE7Et+n5YaN24cw4YNo3PnznTt2pVp06aRlZXlWD01dOhQ4uPjmTx5stN1b7/9NldeeSV16mjqx5+ioqJcLtkXETnTeJtr6a6dN/s47c/MYdW2Q8UGJQWLW7xZml0V0yj8HtwMGTKE/fv389hjj5GamkqHDh2YP38+0dHRgFkt1mp1nj3bvHkzy5Yt44cfvNvGQEREpDx5WzHYXbtxl5zFT5u9q/pesGKquKCkqo7KeMOvq6X8wVO2tVaySHnT3zGRqsddxeCCEOLUisGu2pXUhyPPqXIjLd44Y1ZLiYiIVAR3U0nFVQwGGP/ZerDDw19s8BjYBFqhekgQGcUsz67IPZpOVwpuREREPPA05RQZFlxsnszhY3mMOmUjSndO2OGWKrw8uyIpuBERkTNaaXbOTk3PZtSsNTSo7XmD3QJ1qgdzMMvzBsUAjetWq1R7NJ2uFNwIYO5NNXbsWMaOHevvroiIVJjS7pxdcGzXoeNevc8dFzbliW82FtsuKjyU7k3rnLGJwL6i4Ka82G2w4xc4ug9qREOjHmAN8HevREQkn6dRmdGz1jC2d/Nip5wAIsOKz5O5qXtj3lq2jdT0bK/yaari8uyKpOCmPCTPg/kPQsbek8ci4qDvM5DY33/9qqJsNhsWi6VIyQARqdrKsoefN4nALy76x8XZogZ2jOed5ds95skEB1qZkJToVWE9KTv9NvC15Hnw8VDnwAYgI8U8nuz7PYjeeOMN4uLisNudd4EdMGAAt9xyC1u3bmXAgAFER0dTo0YNunTpwsKFC0v9flOnTqVt27ZUr16dBg0acMcdd3D06FGnNsuXL+fCCy+kWrVq1KpViz59+nD48GHArEL97LPP0qxZM0JCQmjYsCFPPfUUYFb9tVgsHDlyxHGvtWvXYrFY2L59OwAzZ86kZs2azJs3j8TEREJCQti5cye//fYbl1xyCXXr1iUyMpILLriANWuck/iOHDnC7bffTnR0NKGhobRp04avv/6arKwsIiIi+OSTT5zaf/HFF1SvXp3MzMxSPy8R8b35G1I475nFXPfmSu6Zs5br3lzJec8sZv6GFK+u96Zgnt3LNduXJMZ4tY1BQWG9qrjdgYPdBtt+hvWfmK92m1+6oZGb4hgG5B3zrq3dBt/9B9z+W8Bijug0udC7KaqgamApPoq/5ppruOuuu/jxxx/p1asXAIcOHWL+/Pl8++23HD16lH79+vHUU08REhLCe++9R1JSEps3b6Zhw4befbZTWK1WXnrpJRISEvj333+54447+M9//sNrr70GmMFIr169uOWWW3jxxRcJDAzkxx9/xGYz/5KPHz+eN998kxdeeIHzzjuPlJQUNm3aVKI+HDt2jGeeeYa33nqLOnXqEBUVxb///suwYcN4+eWXMQyD//3vf/Tr149//vmH8PBw7HY7l112GZmZmcyaNYumTZuSnJxMQEAA1atX59prr+Wdd95h0KBBjvcp+Dk8PLzEz0lEykdx00neBAoFhfCKExEaSGb2iWKnkgKsFq/yZKp0Yb1KNGuh4KY4ecfg6Tgf3cww/9CneLkr+cN7Ibh6sc1q1arFZZddxgcffOAIbj755BPq1q3LRRddhNVqpX379o72TzzxBJ9//jnz5s0rdg8vV05NOm7cuDFPPvkko0aNcgQ3zz77LJ07d3b8DNC6dWsAMjMzefHFF3nllVcYNmwYAE2bNuW8884rUR/y8vJ47bXXnD7XxRdf7NTmjTfeoGbNmixZsoQrrriChQsXsmrVKjZu3MhZZ50FQJMmTRztb731Vnr06EFKSgqxsbGkpaXx7bfflmmUS0RKztN0U3HTSRZg0lfJXJIY4zFgiAr3rojmiPOaeL0029s8GZ/l01Sm3M6CWYvCfzIFsxaD36vQAEfTUlXEDTfcwKeffkpOTg4As2fP5tprr8VqtXL06FHuv/9+WrVqRc2aNalRowYbN25k586dpXqvhQsX0qtXL+Lj4wkPD+emm27i4MGDHDtmjnAVjNy4snHjRnJyctye91ZwcDDt2rVzOrZv3z5GjhxJ8+bNiYyMJCIigqNHjzo+59q1a6lfv74jsCmsa9eutG7dmnfffReAWbNm0ahRI84///wy9VVEvFfcdFNx00kGkJKezapth9y2sdkNlm3Z77EflX7n7OR5MK0NvHsFfDrCfJ3WplxSH4plt5kjNp4ymOY/VKFTVBq5KU5QNXMExRs7foHZg4pvd8MnZoTtzXt7KSkpCcMw+Oabb+jSpQs///wzL7zwAgD3338/CxYs4Pnnn6dZs2aEhYUxaNAgcnOLr7lQ2Pbt27niiisYPXo0Tz31FLVr12bZsmWMGDGC3NxcqlWrRliY+7oPns4BjqTgU3cFycvLc3kfS6Epu2HDhnHw4EFefPFFGjVqREhICN27d3d8zuLeG8zRm1dffZWHHnqId955h+HDhxd5HxEpH8XVlLmiXSxrdx7x6l4F006FR4Ga1qvOuI/XsWzLAUfb027n7Eo2SsKOX4rmmToxIGOP2S6hZ4V0ScFNcSwWr6aGAGh6sTm/mJGC6wjWYp5verHPhw5DQ0O5+uqrmT17Nlu2bKFFixZ07NgRMJN7b775Zq666ioAjh496kjOLanVq1djt9v53//+5whEPv74Y6c27dq1Y9GiRUyaNKnI9c2bNycsLIxFixZx6623Fjlfr149AFJSUqhVqxZgjrh4Y/ny5bz22mv069cPgF27dnHgwMn/gbVr147du3fz999/ux29ufHGG/nPf/7DSy+9RHJysmPqTETKlzerl77+07tkYYCM7BMua9hYLWaicFhQAFMGtiUk0Hp67Zxd7CiJxRwlaXl5xU1RHd3n23Y+oODGl6wBZuLUx0Nx+2+BvlPK7S/cDTfcwBVXXMFff/3FjTfe6DjevHlzPvvsM5KSkrBYLDz66KNFVlZ5q1mzZuTl5fHyyy+TlJTE8uXLef31153ajB8/nrZt23LHHXcwatQogoOD+fHHH7nmmmuoW7cuDz74IP/5z38IDg7m3HPPZf/+/fz111+MGDGCZs2a0aBBAyZOnMhTTz3F33//zf/+9z+v+ta8eXPef/99OnfuTEZGBg888IDTaM0FF1zA+eefz8CBA5k6dSrNmjVj06ZNWCwW+vbtC5j5S1dffTUPPPAAl156KfXr1y/VcxIR19zl03izeglgZM8Evly7l/2ZOR73aXr0iw0ujxesgHqgTwsGdIgHqFyjMsWphKMk1Ij2bTsfUM6NryX2N4cEIwrNw0bElftQ4cUXX0zt2rXZvHkz119/veP41KlTqVWrFj169CApKYk+ffo4RnVKqn379kydOpVnnnmGNm3aMHv2bCZPnuzU5qyzzuKHH35g3bp1dO3ale7du/Pll18SGGjG0o8++ij33Xcfjz32GK1atWLIkCGkpaUBEBQUxIcffsimTZto164dzzzzDE8++aRXfXv77bc5fPgwHTt25KabbuLuu+8mKirKqc2nn35Kly5duO6660hMTOQ///mPYxVXgYIptltuuaVUz0jkTGWzG6zYepAv1+5hxdaD2AqtpfaUT7PnsHerUtvER/L4AHOBQuHwo+Dnc4rZWNICvPnzv47+FYzKDOgQT/emdSpHYONuSXUlHCWhRjRYPIUTFoiI9y4dw0csxqnJDWcAT1umZ2dns23bNhISEggN9S6T3q3KlMUuJfL+++9z7733snfvXoKDg316b5/+HRPxgbIUwjuVp20M+raJdZtPUzDGHRZk5Xhe8SPKH448h+5N6xS7meV1b670+l6Vjrsl1X0mw94/YPm04u8x7OuKGbnJ2Atv94H0ggUqbmYtfPCPe0+/vwvTtFR5sQZU3JCg+MSxY8dISUlhypQp3H777T4PbEQqm+ICklOVdnPJ0bPW8Or1Z/PENxs95tMcz7M78mFcKbw9gack3y/X7vHq83tb66ZCuU0W3gtzvcwBrFa3YkZJsg7Ce1eagU3tpnDevfDT0y7q3ExRnRvxr9mzZ3P77be7PNeoUSP++uuvCu5RxXn22Wd56qmnOP/88xk/fry/uyNSrkpSCK8sm0tagPGfbyD9eNFVj4XddXEzXlq0xXFtAXfbE7hL8vW2ho237SqMx2ThAhZodw38OTf/Zxdtjx2CVW9Ct9vBsPtuFuHUGYmQcPhxMhzYDOFxMPQLqNkQOlxfKWYtNC11Ck0ZmEX29u1zPVcbFBREo0aNKrhHVYv+jkllYLMbnPfMYrcJvAWjJMsevJgFyalup5MAxvZuzgsLvduDqTgvXtvB5eold6NJ7hR8vuI2qVz24MWVI7+mwLafzXo1xRn2NRw/7HrqqlYC7Fhu/tz4fDi4BTJ9UDHY1VQZQHANGLkY6rUo2f1KQdNSUmrh4eHaakCkivO2EN6ELzfw1Z8pHqeTpvkosAFzJKV70zplXr0UYLWcnptUliRZuO0gc7l34VESixVWvgbfPwLblxa9tjS1cNxNlQHkHoX9myskuCkJrZYSETnDeJtrMuvXncVOJ536686KnXOsyfS3/sI51mSsnEwQrl09uMjqpgIF1YAL8ml8sXrptNyksqRLqgtyO9sOMl+tAWZttm6joJq7FWMlrBhc7FSZpcKrD3tDIzculLYGjEhx9HdLKpK7JODwEO/+1988qgb/pB0ttl1kWBDdc5bzWNB7xFlObnuw16jN43lDWRd+Po9ensiYDyp2JKXCKwuXdZVsox75hWDd1bHJLwRbXLLwjl/g2EEPDQrVwvHU78pYV8cLCm5OERwcjNVqZe/evdSrV4/g4GCV3hefMAyD3Nxc9u/fj9Vq1UosKbPilnC7SgKOiQylb+tovlrnudJvQU7KxP6tueGtX4vty1MtttFv47Qix2M4xGtB01jXsQlnt+vFdGtHr6oB+1KFVRb2xY7Y1gA4+yZY8oyLkyUoBFuS6S1P/W55BWz+zvt7VSJKKC4kNzeXlJQUxyaQIr5UrVo1YmNjFdxImZS2psyposJDSMvMcTuSMv3GjlySGFNsYm5cRBDLQu+BjL0up50MLFgi4mDserAG+KyuTqXiNielhDVebHnw+nmwf5O57U9u1slzEfHeL6n2NjE5KhHSkl2cyP9bEdkA0ncVfx+okLo6JUkoVnDjgmEYnDhxokjlWpGyCAgIIDAwUKOBUiaeiuEBjpoynhKGw0MD+fXhXiz9e3+xK5MK3g9cB0EfXZpH16Ve1F+pqKJyFc1uM3fjLm4qKT+482jldDN/Jaw23PkbpG0s3RSXo0/u9jksgcDq5oZcuVlu7lWCz1dGWi1VRhaLhaCgIIKCgvzdFRE5A7kb3fBmc8m756zlhLtKePkys0+wble6VzkpBYm57qaTuhrLvftQJZm28GWF9/KuFu+rnJSsA2bdGIBej0L1uqUPBr3Z57DTcFg9o/h7DXoL7Cf8tmdiaSm4ERGpRIrbVqC4zSWLC2wKFKyY8iYnxWMQtM3Hmyb6InelPO7ljq/2elr8BOSkQ0xb6OhlJWJPCvY5dPn5p4At17vgJu+YuRrL070quPqwNxTciIhUEgVTQBbsnGPdRBRHSKMmv6W3ZNSsNTSuU81n71XS6rxugyDHCh93UyBervABD1sPuKnN4mlUpqT3Kq0wL5OVPQV3e9fC6nfN7y971nejIIn9XdfCsQaYeTneKOi3p3tVQgpuREQqgYIpp0utq5jgYkn1pLyhfH+wq+OYFTtdTwmAVtlbYs8vXVa7ejCHs3I9VuftWszO2V5zTIHc5L6NN9MWHuup5G/kMP8h8xesNaCYVT6Xl+xe3nAVSGXshR+fLP7asFrugzvDgO/y+9pmoO/3hHK3z2FpgtLTaM9EBTciIpXAqm2HaJe5lOlB04qci+EQ04OmMTpvLCuCe9Aj95fKVVMmsT+06g8b5zkft1hh4FvejZCUJHfl+GHPozItr/BtbRZXgVS1OnAi20y0DapmTt8UeeL5jh+GDZ9Cu8FFz234FHatNO9xyePF98VXvMnLqYS5NN5ScCMi4gNlXeKclpHFhKD3AHNxyqkKdsueEPQ+yxPqMvDfaUWu93tNmf2bzNfzH4A6zWD+w3D8IOQd9+56b3NXvrkPMnbjflQG2PRVyd6zNNNbBUXyaiWYm0am/OliJCne3JZg62L4/Hbznm0Gnny/Izvgh8fMtueNg8j63vXbV4rLy6mEuTTeUnAjIpVLea9uKcQXdVeKqzvjjfrpa51GYgqzWiCOg1y98yksForUlLFazJoyZ//1DFxyY8VW592/GQ78DdYg6HEXhEbC0TRY8Cj88jJ0uMHcFsATbxOOD2wue38LHDtYhumtfLYcsx5Mrcauc1KwwNf3wJr34NORsOcP+OtT5/ezBEDtBN99rpI4zXJpvKXgRkQqj4pY3XKK+RtSeGLeehocXefIXdlVoz2P9m/rFJR4CoDc1Z1JTc9m9Kw1RfYxcnWv9XvSmbdsDZ286HOAzf1IiKXQdEsAdrpbkyFgH1ijgR5AOfzS2pg/UtLkQjOwAeg0DJY8a47obFkIzS/xfA9vth6oXhda9IM17xbfp7BacPwIHgOT7/7j+njB9FaXEcVMb2GeL5jecpeTcsWLZtC+djaseLnoecMGn94KAcH+GS05jXJpvKXgRkQqh4pa3ZJv/oYUvvjgdeYGvUdc8Cm5Kzm1efyDoXD9KEe1X3ejMpckxnisO2MBJn2VzCWJMQRYLS7vFR4ayLHcE3ShOviqcPWRnRUbKG762nxtlXTyWGikGeCseAV+ean44MYaAH2mwNyhLk7mj/pcPtUMWrwJbrqNhp8m4zafpHFP17tmw8n2v71V/PtA8VNqVitcMQ3++szzNF1Jk5zFLe0KLiL+V+xKGXy687DNbvDTFzN4LWgaMThPBRXkrvz0xQy+/dMclSlcW6ZgVOaVxf94rDtjACnp2SzeuM8xwlO4fWb2CWx2OBHfDXv1aLfjDAYWqFbXuw/41Vhz9VLhUYeCQDF5nsvLSuXILtj7h5k83KKf87lzRoM1ELYtNZc7Fyc3M/+bQlNYEXEng9uCER5Pe4xHxMP595vXRBSaFiy41wVuRm1Kw5sptV2/FpN/dMqom5SZRm5ExP/Kaedhd9NJq7bu5+4881/l7pJ37857mys+7+ixGvC0hf941Y+R768mwGrxWAh/T0YeljrxWLL2OUZ9Tr6fxfy53//gh/HFlNW3gj3XzblSLoP2pGDUpmF3qFHP+VxkfWh9Naz/2BzBGehhJOTYIViQn1zbeyLEd3KdA1KSVT6e8knWf+Ld5/M4vVWCGj6+KvYnXlFwIyL+Vw7/4/c0nZTzzxK6e5G8e1bOBlaS6LZdSXbtsRVTObht5s9YctaAxYqlWl3ISnOcs5y6esVq9fyL/YIHYclkD+9UukDRrY35wU1LNxs19rjTDG42fAa9JkDNBq7bLX7STPCt1xK6j4EAD9vflGSVj7t8Em8TmIub3vJ2ubS37+dtO/FIwY2I+J+P/8fvLsk3JT2bUbPW0N+6ngFe5LdEcaTYNpFhQWQcz8PioqiegZWYyFDGXNSM/36xwe09qnOciUH5eSTnjoWL/+t+9Yo3ZfW94YsRgqwDsDN/GqWVm+Amtj0knG9OTf36OvR5qmibPWvg9/ytAPo97zmwKVDWVT7eFrE7/36IalX25dK+rOQsxVJwIyL+581KGS//x3/q5pLuqvhGcNSrbqVRs9g2t5ybwMbFs9wW1bsyaRSRYZ4jqfsC5xJnOUR2jYaEXvCf4lev+LKsflls/hYMuxnA1Gzovl2Pu83gZvVMsw5OWM2T5+x2s3YNBrQdXLLRpLKs8vHV9FZ5vJ+UmYIbEfGNstSnsQbAheNh3l1uGhhe/49/1bZDpKRn08fFNgapRi2S7Y240LrWvKvhuvyK3YCcajHsCm6PJSPP4zYGd8YmYw1+EaNQqxjLIaYHv4jF2glbQhKxkaGkpmcXuVdby78MC/gegKAB0yAorNjPCJShrD5mXZWIeO/ex5OCJeCnrpJypVlvc7pp/yZzpdO595w8t+Zd2LsGQiLg0ifK3qeS8MX0Vnm9n5SJghsRKTtfLDv+Z4H5ag0Ce57zuRrRRVfiuJGafpw+1lUutzGI5jAxAYcB2F+nK3UPrsJO0WWjFguE9XuKRy1t8zeydLONwRUtCPj+EvLXMjlx3HP+QwS0vJwJSYlF7hWAjaeD3iLAYrC3wRXENe/l1Wf0qNgRAsOsqzKzH9z0BdRtXrqgNDsD/v3J/L5VMX/GFotZ3O/LMbDydTOPJTAYsg7Coklmm4sehvCYkn7asqvoInZVtGheZaPgRkTKxhf1aZK/NPclsgbCrQshJ9P8H39IBHx2m/n9hk+g/bWOS1ythPp3/1FeW7yZd91sY2CxmKM1hwhnS9/Z1MtbWSQoMyxWLIYddiyn7xWDmH6jh20Mqm/xepVX3zY9mX5jR6eigZ2sm2lr3U5eUARxQ17w/IxKwtMIwQX/gZXTzVGUty429zTK2u/cxpug9J8fzPyeOs3NLQaK0/YaWPQ4ZO6Fn6ZAdCL8+ZG571J0G+gysnSf1RcquohdFSyaV9kouBGR0ivpTs6uHD8M39xvfn/uWIjr4Hz+vHtg4USz2m2bQRAQ6LoYXkggx/NsdOYvp6J8hVksUIdMugZsgub9sRT6V7TlRDbMHmQmuDa5kL5tBrjfxmD9cu+eU/puAPpaf6NP6INYcp0DoqD2g6BGlHf38panEYJW/eGtXnDoX3Pjx1N5G5R6OyVVIDDETCxePxeW/c/5XOurIEC/jsR39LdJpCJV8L5J5c4X9Wm+/6+57LnuWa4Lq3UZCctfgkNbYcMnzA+4wOVKqMycEwB0rJMDWUVvU1hAwVJrV/+KPncsLJ9m5gDFnU1AzYZ0b1qn6E28Tcpd8Cjs/h1+fxuX1W5+fweaXOT7nAt3IwShkR4KynkRlOZln5xGdLdKqrDkee5ryyx+0vzzV86J+IgqFItUlOR5MK0NvHsFfDrCfJ3WxrfVYitaWevTbFkEa2cBFuj/CgSGYLMbrNh6kC/X7mHF1oPYgqqb+RqAseRZnpy33mN9me254d71yVNgcvF/Ib4zZKfDJyPAlue63UEvivhZrOa0z+9v4bEyjg8rMBdrxy+QmeKhQTHVcv/9EfKyzKTkuI7Fv5/HEb58Ffn5pcrTyI1IRajgfZMqjNf1afKnXE4duQqJgK/Hmce73Q4Nu7ktvPd43yQuCXsZy6GtdM79kd2c5/at5mc24UR4DQLz3C339mJZeUAQDHobXu8Ju1fBj09B014nR9wadoefnoafT51ecZN2fPWb5mf+/W337+frwnrFKWtQWlC4r1VS8bt9Q7lVoBZxR8GNSHnzRV5KZWQYsG2Jd21/eRUO7zADgsK/5KrVhYsf9Vh4b+RHf/No5BWM4D3uCvycr3K7Y3Ozu3VP63oCPAU24N2y8lqNof9LMPdmWPaC+VUgKOzktM4FD0J0a/PP0NPyXo/BTb6KKr1flqKJthOw+Rvze3dViQvT1gNSwRTciJQ3f/2r1Zf5PYXvVb8rfPdAod2Z3Sw7tgbCP/PNL1eOHcC2ZRGTvqrhcbppavoFXB3yGU2tKSRZV/CFvejoTSNLKi8FvWyGME0uggOby1ZPxOLmeRUENl1GmkuYwfxF7+55V7bS+97Uwgmt6Xp0a8dyMwm8Wh1zBMsble3zS5Wn4EakvPnjX60lqTtTXBDk6l6BoXAi28wn6fc8VK/nvjBZrcbw5kVgP+GmsxZOfPMg+9Kfw1MaYBZh7E28lVobp3F34OfMy+2B/ZT21cjmjaCpRFqOYdTviuX6j8zAqrQBnmPEzYPN38Jlz5j39LS8t7KV3vdYCydf9hGzonCXEc7HCzbKbHGZ9yucKtvnlypPwY1IeSuPf7V6CkhKkt9TXBDk7l4n8nNietx18pefp+0A3AY2AAYhx1Loat3ESrv7TSoBtje5geZb36FJbgoDrMtIoW7+1gqRDA34gRbW3WSH1iN0yPvm0mMo/WhYsSNueD/iVhlL77uthRMPMW3h7/nwzThze4WuI82/c9uXw58fm+1aeDklBZXz80uVpuBGpLx5MwVQra73/2r1FJC0vNz7/J5N33gOggbNhB/Gu+8zmEt7e00AawA2rKyyJ5Jma0KUPZSuWM2sGC9HpLzZpLJ27ToE97wHFj3Oc8FvEIjd6bydAEKvn+2bSre+HnGrjKX33dXCsVjN5eu/vAzf3g8p62DrIud+f3OvWUna235Xxs8vVZbfg5tXX32V5557jtTUVNq3b8/LL79M165d3bY/cuQIjzzyCJ999hmHDh2iUaNGTJs2jX79vCvNLlLhnP7V6kZ2OmxfBk0u8Hyv4kZlLhzvXX7Pwomw7sOi9yloAzDvTsjN9Nyf/JGL+VnNXK5ympCUyCXVo9yk/jo7ElCLQrGKQ8E+Tl0TakNWfYAigQ2AFZvvpvfKY8StMpbedzeddskTZs7R8mnwx/tFz2emlnylX2X8/FIlWQzD8JTDV64++ugjhg4dyuuvv063bt2YNm0ac+fOZfPmzURFFa3WmZuby7nnnktUVBQPP/ww8fHx7Nixg5o1a9K+fXuv3jMjI4PIyEjS09OJiIjw9UcScW/p/2Dx487HIuKhehSk/AGBYXDjJ2aSpqv/+dttZl0cT8GLxWpOI1SgdV2f58qlcUXCpIIFwvf2asKgZf2I4VCR7RDA3KQylTp8ct63vLBoK+B6H6fpN3akb2JUMc8gP3dj7Pqy/8J0PO9i8kR88V6Vle0EPNMIcotZVl+Vn4FUGiX5/e3XkZupU6cycuRIhg8fDsDrr7/ON998w4wZM3jooYeKtJ8xYwaHDh3il19+ISgoCIDGjRtXZJdFSi+4mvlav6tZ16UgcLGfgDk3wJYF8P7VEBIOxw6cvK5gyimsVvE5IN4GNhENIGNX6T5HIf/3xzFP4z9MW/wvf1mGMj1oGnbDeb8ne36jSXk30a9euOd9nNrEmvk7FbXyTHkisHOFh8AGVJ9GKiu/VSjOzc1l9erV9O7d+2RnrFZ69+7NihUrXF4zb948unfvzpgxY4iOjqZNmzY8/fTT2Gzuq1rm5OSQkZHh9CXiF3v/MF+b9Ya2g8xfBtYAM/F1yCxz80BbjnNgAyennJZN8+59QmtycryjMIs5WnTlq17dKie4liMAKcxuQGZwNPMzm3i8h92A7+1dGZ03llRqO51LpQ6j88byvb0rUeGh9G0Ty7IHL+bDkefw4rUd+HDkOSx78GIzsIGKX3lWkCcSEet8PCLu9C28WBKqTyOnKb+N3Bw4cACbzUZ0tPN8dXR0NJs2bXJ5zb///svixYu54YYb+Pbbb9myZQt33HEHeXl5TJgwweU1kydPZtKkST7vv0iJ7Vljvsa7KFcfEATHDrq5MD+62LrQu/c55w74aTIeRxsanwcRcRgZKS73OjLypxsmHbuOJ3ne7YjLf7Kuc1qO7U5kWCA/HO/KgpzOdLVuyl/hVJNV9pYYWIktyKcBAqwW1/s4gX/qpZzJeSKqTyOnqdNqbym73U5UVBRvvPEGnTp1YsiQITzyyCO8/vrrbq8ZP3486enpjq9du3wzFC9SItkZJ/chiju76Pli9/rJFxjm4WT+qMz59xc/2mAN4I/WD2EYRpGRGbsBhmHwbsQoPjja0eOIy3c298n/p7rlXHN0x8DKSnsi8+w9WGlPxMj/X9CEpERzl+3iFKw8K25kytf1UgqSbk8dcTsT+Ot5i5SR30Zu6tatS0BAAPv2OQ9n7tu3j5gY18s4Y2NjCQoKIiDg5P9YWrVqRWpqKrm5uQQHBxe5JiQkhJCQEN92XqSkUtaar5ENoXrdoue9HdbvPBxWTs//wUMOSDGjDTa7wR1r6tMubywTgt4jjkOOO6VSh0l5N/H9lqaAOaXkasSlYMQmIjSQzOwT7lJuiYkM5c6Lm9EipobnfBpvKA+mYul5y2nKb8FNcHAwnTp1YtGiRVx55ZWAOTKzaNEi7rzzTpfXnHvuuXzwwQfY7XasVvN/rH///TexsbEuAxuRSqMg3yaug+vz3g7rt+hnrqbyolaI27ozwKpth0hJzyYFz4FLAXv+iIsrI85rwrSFf7v71ecYlenbJpZLEmNYte0QaZnZRIWbU1FejdicSvVSKpaet5yG/Lpaaty4cQwbNozOnTvTtWtXpk2bRlZWlmP11NChQ4mPj2fy5MkAjB49mldeeYV77rmHu+66i3/++Yenn36au+++258fQ6R4nvJtoGTl6a0BxeaAuNtde0JSIu0b1OStn/91HPcUuNQMCyL9eJ7PRmU85tOUxJmcB+MPet5ymvFrcDNkyBD279/PY489RmpqKh06dGD+/PmOJOOdO3c6RmgAGjRowPfff8+9995Lu3btiI+P55577uHBB4vZ/0XE3xwjNy7ybaDkw/8e9jHytLv2qFlrsFpwuwKqsOHnJlTsqExJeNrLSXxPz1tOI34t4ucPKuInFe7YIXg2wfz+wR0QVtN9W5dbK8R7Pfxvsxuc98xipxEUV7o2rsk/aVkcOeZ5VGbZgxezIDnV7SiQ17kyIiJldNoU8RM5I+zNn5Kq3dRzYANeD//b7IbLUZKCXJri3HtJS9KP5zJ61prKOSojIlIGCm5EyltxU1KFFTP87ymfJivH0+7bJ6VlZjOgQ3zxFYHz+SxXRkSkAii4ESlve/KDG3fJxCXgLp8mNT+fpnqwd6WrosJDATQqIyJVkoIbkfJW0pEbN2x2g0lfJXvcxykr1+4xYdhpd+18GpURkarmtKpQLHLayUyFzL3mbt0x7cp0K2/zacZc1BQLRWvKFs6lERGpqhTciJSnglGbui0gpIZXl9jsBiu2HuTLtXtYsfUgtvxhmLTM4gMbgGZR5u7aMZGhTsdjIkOZfmNHrXASkSpP01Ii5amgeJ+XU1LukoXH9m7Oks37vbpHVHgo3ZvWUS6NiJyxFNyIlKe93icTeyq+9+Cn64u9vnA+jXJpRORMpWkpkeLYbbDtZ1j/iflqt3l3nWGcrHFTzMiNp2ThAkEBFsZcqHwaEZHiaORGxBOXFYPjzK0SiqsYnL4Ljh0EayBEt/HY1Jtk4TybwXnN69G2fmTZd9cWEanCFNyIuJM8L3+vp0LjKRkp5vHB73kOcAqmpKISIchM7nVXWXjvkWNedamg+J7yaURE3FNwI+KK3WaO2LitKmOB+Q+ZWyW42xm50E7grpKFYyJC6dc2hq/+3OvqDkUUFN9TPo2IiHsKbkRc2fGL81RUEQZk7DHb5W+VUHhU5py9f5i5MHFnu68snJHNjOXbAUpcfE9ERFxTcCPiytF9JWpXeFTGgp0/Q38jHLDFns2kdz0nC4eHBPL4gNaM+3gd4HkjSxER8UyrpaTqKu0qJzB34/ayXcGozKnTTY0s+wjnGDlGEHcuOF5ssnBmzgliIsNUfE9ExAc0ciNVU1lWOQE06mG2z0jBdd4NEBGPrUF3Jj23pEiLdpZ/zW4Yjfhu40GvuqxkYRER39DIjVQ9BaucCufMFKxySp5X/D2sAWYg5Gkyqe8UVu1Idzkq085qBjfr7E287nbhZOEBHeLp3rSOAhsRkRJScCNVS7GrnDBXOXkzRZXYH+I7uT1t1E5gYbLr3JyC4GZ9fnBTMyyoSOG9AhbMLRaULCwi4hsKbqRqKckqp+Jk7MW+dy0A43JHcXfunVyb+18WWroDsGrG/by9fFuRy6zYaWPZDsA6wwxuhp+bAKiysIhIRVDOjVQtJVzl5Mk/81+juWHjV3tLPrOf7zi+PzuSi4JX0i13JZ0Dk9gU0IysHJtjrKiZZQ/VLDlkGSFsM+KIjQzlzoub0SKmhioLi4hUAAU3UrWUYJUTuK8YbDuRR0TyBwDMPtHb6dKtRjxf2M9lYMAyZjVdyE9dBjJ61hosmBNfBVNSG4wE7FgdozJ928QqWVhEpAIouJGqxbHKyd3UlMU836iHy4rBsfkjKY0PLKUlBzlohDPf3qXIXV48MZAB1l8I3fEjfXvtZPqNHR33apu/UmprUHOmD3Zewq3KwiIi5U85N1K1OFY5edB3CvOT04rUpgFITc9m1Kw1pC97A4C5tgvIJajILXYa0cy1XWD+8OOT9G0Ty7IHL+bDkefQv14qANcOuFLTTSIifqDgRqqemg3dn2tyIbaWSUz6ynXFYAOob9lPl7zVAHxou9jtrV4+cRV2azBsWwrblpqjMo3CqZXxNwDW+LPL8CFERKS0FNxI1fPj0+Zrm0Ew7GsY+PbJ0Zx/f2LD6p89Vgy+NmAxVovBL7RjpxHjso0FMCLrQ6dh5oHFT4FhQFoy2HIgNBJqe1/jRkREfEc5N1K17PoN/vkeLAFw0cNQp+nJc7tXwYZPqb9yAnAfRRdmQyAnGBLwk9m8yRBIxpEoXODU5dvWhonwx/uwayX8/QNsW2KerNUYDLvZDxERqVAauZGq5ccnzdcO12Gr1YQVWw/y5do9rNh6EFuvSRAYRp2Da+hvXeHy8kusq6lnSSfNqEnD7oOK3+spIha63Gqe+OgGWPmq+X3KOpjWxrtqyCIi4lMauZGqY/sy+PcnsAaxJOZmHnpmsdP0U3RECOPDr+XKw+8wPugDFuR05DjOgcsNAQsB+CawN0ObRhNgtRS/fLteK/PVnufcn4LtHga/591+ViIi4hMauZGqwTDMvBdgZ+NB3Px5WpG8mn0ZOTyYcgG77PWItRxidOA8p4mpxpYUzgv4C7thIeHS0Y4AxuNeT3Yb/PSUu06ZL95u9yAiIj6h4Eaqhn9/hJ2/YASEcOfui91ud5lDMC8GmEnAY4K/pWPEEce56wIWA3Ag9nwu7NbZu/f15XYPIiLiEwpupPKx22Dbz7D+E/O1uFEPw4DFZq5NSvPr+TOjusfmnxw/myMxPQiw5/JJwjd8kwSf9tjOiDAzGTjqotHe99WH2z2IiIhvKOdGKpfkeeau3qeOhkTEmUu53eWt/P097FkNQdX4s/FwWLu7mDexsCbxQS5OvQrL5m9ovfmbU04FwIkc7/tbwu0eRESk/GnkRiqP5HlmAm7haZ6CxNxTVh7ZTpzgr+Xf8PtX/8fxr/5jHusyksXFxTX54m17AHvRE4YN5t7s/Sqngu0eXCwrN1kgIt5sJyIiFUIjN1Jx7DYz9+ToPnMko1EPc7uEgnPzHwS3dYMtZmJuy8v5Y8Es4lZMojUHT94amLzKzsdHPUc3FiAuIoiz/njSc1/z38vRP3cKtnv4eChuK+L0nVL8fURExGcU3EjFKG66ycvE3H8+mUD7v142D50yWGIx4OG8l0kLDqJOl0HMXL694KqTbfJfXzjnGJalXiYBJ/Qs/rMl9jeXe7v8fFO0DFxEpIIpuJHyVzDdVHhUpmC66dInzfo0XmiY/DoWwFJoFshiMfOKH7a+S73LHqFbQu0iO37H5O/43dVY7l2/S5IEnNjfHOlxNzIlIiIVRsGNlK9ip5uAHx7x+nYh5LlNb7FaIIaD/PXr9/Q993L3xfe2lVMSsDXAu5EeEREpVwpupHwVO92Ur0F3OPg3HDuE60DIQl5AGEG2Y8Xe6vjhPcDJ4ntFFCQBZ6S4fS8i4pQELCJymtJqKSlf3k7tdL0VrpiW/0PhoRnz5/WNhnl1q7Ba8Z4bFCQBe3gvJQGLiJy+FNxI+SpJHZj8xFwjItbplBERxw9tnmXwxnPZa9TG7qb8sN2AVOrQsluf4t+vIAm40HsREae9oERETnOalhLfcLXM22I1Vx0VWSJ9KucpoPn2LjyR/SINctcRxRHSqMm6Q4kcTzNbz655B/cdeRK7YebYON4+//Yp3ScQE+jlX2slAYuIVEkKbqTsXC3zDo+Bmg1h16pTGnquAzN/QwqjZ63BAPaQeLJZfq2967s24P6r+rH2hyjiVkwi+pQ6N2mWOqR0n8DZfbybunJQErCISJWj4EbKxt0y78xU8wsrXDQe6jSHHx52WwfGZjeY9FWy2/EdgB8378duwNl9hmHrdQN//fo9xw/vIaxWPC279fF+xEZERKo0/TaQ0vO4zDtf9TrQ8z6wBmBrmcSmQgFJQH5AsmrbIaeaNK6kpGezatshujetQ0BgIK3PvdyHH0ZERKoKBTdSet4s887aDzt+YX5Ws/yiegDmaqbYpUuYkJTIRS2j+GLtHq/eMi3TcwAkIiKi4EaK525PKC+Xea/buInRSzOKjO+kpmczatYaaoYFceR4nlf3igoPLWHnRUTkTKPgRjxztyfUxY/Bpm+8usX//XHMU31ijhzPo16NILJPGBzNPuGurB4xkWaVYREREU8U3Ih7bveE2gtfjPLiBhZyqsUw/1CTYlv+b3AHjuXaGD1rjbs1VUxISjS3TxAREfFARfzENW+Sha2B0PMBzPDDdaXfdW0ewu7FX7PDx/Lo2yaW6Td2JCbSeeopJjKU6Td2pG+bWDdXi4iInKSRG3HNm2Rh+wlocgHEtnM9ddV3CraQc2HpymLfriCXpm+bWPcbXoqIiHihUozcvPrqqzRu3JjQ0FC6devGqlWr3LadOXMmFovF6Ss0VEmmPuftnlBH95mVfsdugGFfw8C3zdex6yGxP10a16JGiPsY2gLEFsqlKdjwckCHeHPZtwIbEREpAb+P3Hz00UeMGzeO119/nW7dujFt2jT69OnD5s2biYqKcnlNREQEmzdvdvxsseiXn8+VZE8ocFnp1zAMnvt+M0dzTri8VLk0IiJSHvw+cjN16lRGjhzJ8OHDSUxM5PXXX6datWrMmDHD7TUWi4WYmBjHV3S0l7+IxXuNephTS25ZICLesSeUzW6wYutBvly7hxVbD5J3ws6jX27g/5b+C8CgTvWJVS6NiIhUAL+O3OTm5rJ69WrGjx/vOGa1WunduzcrVqxwe93Ro0dp1KgRdrudjh078vTTT9O6deuK6PKZwxoAfZ+Bj29ycbLonlBmgb6TBfbCgqwcz7NjscDTV7Xluq4NsdkN5dKIiEi582twc+DAAWw2W5GRl+joaDZt2uTymhYtWjBjxgzatWtHeno6zz//PD169OCvv/6ifv36Rdrn5OSQk5Pj+DkjI8O3H6Iqq9vc9fFT9oQ6dbPLUx3PM3e7HN6jMdd1bQiczKUREREpT37PuSmp7t270717d8fPPXr0oFWrVvzf//0fTzzxRJH2kydPZtKkSRXZxapj2Qvma8sk6HZ7kQrF3mx2+d2GVB65XDk1IiJScfyac1O3bl0CAgLYt895Zc6+ffuIiYnx6h5BQUGcffbZbNmyxeX58ePHk56e7vjatWtXmft9Rji0DdZ/Yn5//v1msnDbQearNQAo2WaXIiIiFcWvwU1wcDCdOnVi0aJFjmN2u51FixY5jc54YrPZWL9+PbGxrpNSQ0JCiIiIcPoSLyx/EQwbNOsNcR1cNvF2E0ttdikiIhXJ79NS48aNY9iwYXTu3JmuXbsybdo0srKyGD58OABDhw4lPj6eyZMnA/D4449zzjnn0KxZM44cOcJzzz3Hjh07uPXWW/35MaqWjBRYO9v8vud9bpt5u4mlNrsUEZGK5PfgZsiQIezfv5/HHnuM1NRUOnTowPz58x1Jxjt37sRqPTnAdPjwYUaOHElqaiq1atWiU6dO/PLLLyQmJvrrI1Q9K14BWy407OFY6u1K14TaxESEkprhemRGm12KiIg/WAzD8JQPWuVkZGQQGRlJenq6pqhcOXYIXmgDeVlww6fQvLfH5mPn/MEXa4tu01CQPqw6NiIi4gsl+f3t9yJ+Usn8+roZ2MS2h2a9PDZN3pvBN+tTAIgMC3I6pwJ9IiLiL36flpJKJCfTDG7AzLXxsK1Fzgkb4z5eS57N4NLEaF67oSO/bT+sAn0iIuJ3Cm7kpN/ehux0qHuWWdvGg6k//M2m1Ezq1gjm6avbEhhgVYE+ERGpFEo8LdW4cWMef/xxdu7cWR79kYpmt8G2n2HtByeL9p13L1jd/9VYte0Qb/xs7hn19FVtqVsjpCJ6KiIi4pUSBzdjx47ls88+o0mTJlxyySXMmTPHaXsDOY0kz4NpbeDdK+CL0ZB9BCwBEBjm1OzUTTEXb0pj3Md/YBhwTaf6XNrau2KLIiIiFaXUq6XWrFnDzJkz+fDDD7HZbFx//fXccsstdOzY0dd99CmtlsqXPA8+HgouN0+wwOD3HHtHFd4UE6BO9WB+euBCwkODXFwvIiLiWxWyWqpjx4689NJL7N27lwkTJvDWW2/RpUsXOnTowIwZMzjDVpifXuw2mP8grgObfPMfYv763YyetcblFgsHs3JZvuVA+fVRRESklEod3OTl5fHxxx/Tv39/7rvvPjp37sxbb73FwIEDefjhh7nhhht82U/xpR2/QEbR2jQnGZCxh3nzPnUb/liASV8lY7MriBURkcqlxKul1qxZwzvvvMOHH36I1Wpl6NChvPDCC7Rs2dLR5qqrrqJLly4+7aj40NF9xbcBArPSgGYuzxmc3BRTq6RERKQyKXFw06VLFy655BKmT5/OlVdeSVBQ0ZyLhIQErr32Wp90UMpBjWivmqVRs/g22hRTREQqmRIHN//++y+NGjXy2KZ69eq88847pe6UlLNGPaBaXTjmLmfGQk61GFZlt3Rz/iRtiikiIpVNiXNu0tLS+PXXX4sc//XXX/n999990ikpZ0d2wInjbk6aVYUDL3+G6Mhqbm9hAWK1KaaIiFRCJQ5uxowZw65du4oc37NnD2PGjPFJp6QcHT8CHwyB3CyolQDhhfZ+ioiDwe8R0HoAN53jeoSuYFOFCUmJ2mJBREQqnRJPSyUnJ7usZXP22WeTnJzsk05JObGdgE+Gw4G/ISIebpkP1euZq6eO7jNzcRr1AGsAeTY7X+bv9h0WFMDxPJvjNjGRoUxIStSmmCIiUimVOLgJCQlh3759NGnSxOl4SkoKgYHaqqpSsducA5e/PoetiyGoGlz3IYTnVxdO6Fnk0jd//pfN+zKpVS2IH+69gC1pR7UppoiInBZKHI1ceumljB8/ni+//JLIyEgAjhw5wsMPP8wll1zi8w5KKSXPMwv1uapnc/WbENve7aU7Dmbx4sJ/APjv5YnUCw+hXrj2jxIRkdNDiYOb559/nvPPP59GjRpx9tlnA7B27Vqio6N5//33fd5BKQWPWysAht3tpYZh8N8vNpBzws65zepwdcf48umjiIhIOSlxcBMfH8+ff/7J7NmzWbduHWFhYQwfPpzrrrvOZc0bqWDFbq1ggfkPQcvLwRpQ5OyXa/fy8z8HCA608uSVbbFYNP0kIiKnl1IlyVSvXp3bbrvN130RX/ByawV2/FIk1+ZwVi6Pf20mhd/TqzkJdauXY0dFRETKR6kzgJOTk9m5cye5ublOx/v371/mTkkZeLm1QkE7m91g1bZDpGVm89ma3RzKyuWs6BqM7NmkmBuIiIhUTqWqUHzVVVexfv16LBaLY/fvgukLm83m6XIpb15urUCNaOZvSGHSV8lFdv0e0CGO4MBS76kqIiLiVyX+DXbPPfeQkJBAWloa1apV46+//mLp0qV07tyZn376qRy6KCXSqIdZiA93uTIWiIhn/tEERs9aUySwAXj++7+ZvyGlXLspIiJSXkoc3KxYsYLHH3+cunXrYrVasVqtnHfeeUyePJm77767PPooJWENgL7PuDmZP7rWZzKTvt7sNuUYYNJXydjsnlqIiIhUTiUObmw2G+Hh4QDUrVuXvXvN5NVGjRqxefNm3/ZOSiexPwx+DyyF/njzt1ZYFXqeyxGbAgaQkp7Nqm2HyrefIiIi5aDEOTdt2rRh3bp1JCQk0K1bN5599lmCg4N54403ilQtFj86q+/JejaXvwB1mzu2Vkhbu8erW6Rlug+AREREKqsSBzf//e9/ycrKAuDxxx/niiuuoGfPntSpU4ePPvrI5x2UUsrMXw4eGAqdh8Mp9WqiwkO9uoW37URERCqTEgc3ffr0cXzfrFkzNm3axKFDh6hVq5YKvlUm6bvN18j6ToENQNeE2sREhpLqZmrKgrk5ZteE2uXcSREREd8rUc5NXl4egYGBbNiwwel47dq1FdhUNqcGN4UEWC1c3tb1jt4Ff4oTkhK1OaaIiJyWShTcBAUF0bBhQ9WyOR2k7zJfXQQ3OSds/JCcCkCNEOfBu5jIUKbf2JG+bVwHPyIiIpVdiaelHnnkER5++GHef/99atfWtEWl5Ri5aVDk1PsrdrDr0HGiwkNYdN8FbNiTQVpmNlHh5lSURmxEROR0VuLg5pVXXmHLli3ExcXRqFEjqld33n9ozZo1PuuclMER1yM3R47l8vLiLQDcd+lZhIcG0b1pnYrunYiISLkpcXBz5ZVXlkM3xOfc5Ny8sngL6cfzaBEdzqBORUd1RERETnclDm4mTJhQHv0QXzIMl9NSOw8e470VOwAY36+lpp9ERKRK0u6IVdHxw5Bn1iIy95kyPfv9JnJtdno2r8sFZ9XzU+dERETKV4lHbqxWq8dl31pJVQkUjNpUrwdBYQD8sfMwX/+ZgsUC4y9rpaX7IiJSZZU4uPn888+dfs7Ly+OPP/7g3XffZdKkST7rmJRBoXwbwzB4+tuNAAzsWJ/EuAh/9UxERKTclTi4GTBgQJFjgwYNonXr1nz00UeMGDHCJx2TMsgPboyI+qzcepCFyfv4bfthQgIt3HfpWX7unIiISPkqcXDjzjnnnMNtt93mq9tJWeQX8PvoH4OH1q50HA4KsLJu1xFiI8P81TMREZFy55OE4uPHj/PSSy8RHx/vi9tJGaXsNOvY/JNd0+l4Vo6N0bPWMH9Dih96JSIiUjFKPHJTeINMwzDIzMykWrVqzJo1y6edk5Kz2Q0O7NlKLLDHqOt0zsDcO2rSV8lckhijpeAiIlIllTi4eeGFF5yCG6vVSr169ejWrRu1atXyaeek5FZtO0Rj+36wwF6jaOVhA0hJz2bVtkOqTCwiIlVSiYObm2++uRy6Ib6yPz2TbhwGYG+hkZtTpWVmV1SXREREKlSJc27eeecd5s6dW+T43Llzeffdd33SKSm9+gHpWC0GOUYQB3C/5DsqPLQCeyUiIlJxShzcTJ48mbp1i44IREVF8fTTT/ukU1J67SMyAdhj1MHMsHFmAWIjzd2/RUREqqISBzc7d+4kISGhyPFGjRqxc+dOn3RKSi8gYw/gOt+mINSZkJSoZGIREamyShzcREVF8eeffxY5vm7dOurUUYKq36WbAeZeoy7BAc4BTExkKNNv7EjfNrH+6JmIiEiFKHFC8XXXXcfdd99NeHg4559/PgBLlizhnnvu4dprr/V5B6Vk7Ed2YQX2UodnBrYjJjKMtMxsosLNqSiN2IiISFVX4uDmiSeeYPv27fTq1YvAQPNyu93O0KFDlXNTCRza+y91gfSgaPq1iyUkMMDfXRIREalQJQ5ugoOD+eijj3jyySdZu3YtYWFhtG3blkaNGpVH/6SEcg6a01JntWilwEZERM5Ipd5bqnnz5jRv3tyXfZEy2nUwi1q5+8ACPTud7e/uiIiI+EWJE4oHDhzIM888U+T4s88+yzXXXOOTTknpfLbiL2pYzOJ89Rsr8BQRkTNTiYObpUuX0q9fvyLHL7vsMpYuXVqqTrz66qs0btyY0NBQunXrxqpVq7y6bs6cOVgsFq688spSvW9VknvCzso/1gGQE1IbgrTzt4iInJlKHNwcPXqU4ODgIseDgoLIyMgocQc++ugjxo0bx4QJE1izZg3t27enT58+pKWlebxu+/bt3H///fTs2bPE71kVLUjeR7Xj5m7fQbUb+rk3IiIi/lPi4KZt27Z89NFHRY7PmTOHxMTEEndg6tSpjBw5kuHDh5OYmMjrr79OtWrVmDFjhttrbDYbN9xwA5MmTaJJkyYlfs+qaPavO4izHATAGlnfz70RERHxnxInFD/66KNcffXVbN26lYsvvhiARYsW8cEHH/DJJ5+U6F65ubmsXr2a8ePHO45ZrVZ69+7NihUr3F73+OOPExUVxYgRI/j55589vkdOTg45OTmOn0szulTZbd1/lF+2HuSCQDO4IbKBfzskIiLiRyUObpKSkvjiiy94+umn+eSTTwgLC6N9+/YsXryY2rVLtl/RgQMHsNlsREdHOx2Pjo5m06ZNLq9ZtmwZb7/9NmvXrvXqPSZPnsykSZNK1K/TzYe/msu/O0QehSxAIzciInIGK/G0FMDll1/O8uXLycrK4t9//2Xw4MHcf//9tG/f3tf9c5KZmclNN93Em2++6XLzTlfGjx9Penq642vXrl3l2seKlp1n45M1uwFoEZZuHlRwIyIiZ7BS17lZunQpb7/9Np9++ilxcXFcffXVvPrqqyW6R926dQkICGDfvn1Ox/ft20dMTEyR9lu3bmX79u0kJSU5jtntdgACAwPZvHkzTZs2dbomJCSEkJCQEvXrdPLdhhSOHMsjvmYYkbn5z1HTUiIicgYrUXCTmprKzJkzefvtt8nIyGDw4MHk5OTwxRdflCqZODg4mE6dOrFo0SLHcm673c6iRYu48847i7Rv2bIl69evdzr23//+l8zMTF588UUaNDgzfqnb7Aarth0iLTOb6T9tBeD6TrFYfjFXS2nkRkREzmReBzdJSUksXbqUyy+/nGnTptG3b18CAgJ4/fXXy9SBcePGMWzYMDp37kzXrl2ZNm0aWVlZDB8+HIChQ4cSHx/P5MmTCQ0NpU2bNk7X16xZE6DI8apq/oYUJn2VTEp6ttPxhsHpYNghIASq1/NT70RERPzP6+Dmu+++4+6772b06NE+3XZhyJAh7N+/n8cee4zU1FQ6dOjA/PnzHUnGO3fuxGotVWpQlTN/QwqjZ63BcHFu1vxlJIUAkfGg5yUiImcwr4ObglVKnTp1olWrVtx0001ce+21PunEnXfe6XIaCuCnn37yeO3MmTN90ofKzmY3mPRVssvABnDUuDEi6mOpuG6JiIhUOl7/E/+cc87hzTffJCUlhdtvv505c+YQFxeH3W5nwYIFZGZmlmc/z3irth0qMhV1qljLAQD2B2hKSkREzmwlnr+oXr06t9xyC8uWLWP9+vXcd999TJkyhaioKPr3718efRQgLdN9YAMQnz9ycygwqiK6IyIiUmmVKTmjRYsWPPvss+zevZsPP/zQV30SF6LCQz2ej8sfuQmqpX2lRETkzOaTzNOAgACuvPJK5s2b54vbiQtdE2oTGxnqNp+mIOemcdOWFdcpERGRSkjLak4TAVYLE5Jc1xKyYBCfP3ITUOvMqPUjIiLijoKb00jfNrGM6JlQ5HizCDs1LPk5ORHxFdwrERGRyqXU2y+If2xONVelXXV2HBe2iCIqPJSu1fbC/wHV6kBwNf92UERExM8U3JxGdh8+xrIt5vTTvb1b0LBOfiCz+TfzVdsuiIiIaFrqdDL3990YBvRoWudkYAOQnr/TuTbMFBERUXBzurDZDT5ZvRuAIV0KBTHp5nGN3IiIiCi4OW0s23KAPUeOExkWRJ/WMc4nFdyIiIg4KLg5TXz8mzn1dGWHOEKDApxPKrgRERFxUHBzGjiUlcsPyakADOniogKxI7hRzo2IiIiCm9PAZ2t2k2czaBsfSWJchPNJWx5k7jW/V3AjIiKi4KayMwyDj383p6SKJBIDZKaAYYeAYKiuHcFFREQU3FRya3cd4e99RwkNstK/Q1zRBgVTUhHxYNUfp4iIiH4bVnIf5ScS92sTS0RoUNEGSiYWERFxouCmEsvKOcFX68x8GpdTUqACfiIiIoUouKnEvlmfQlaujYS61emaUNt1I43ciIiIOFFwU4kVTEld07k+FovFdSMFNyIiIk60cWYlY7MbrNp2iPV7jrB6x2GsFhjU0UPgouBGRETEiYKbSmT+hhQmfZVMSnq241hQgJU1Ow/Tt02s64tUwE9ERMSJpqUqifkbUhg9a41TYAOQc8LO6FlrmL8hpehF2emQk2F+HxlfAb0UERGp/BTcVAI2u8Gkr5IxPLSZ9FUyNnuhFgWjNmG1Ibh6ufVPRETkdKLgphJYte1QkRGbUxlASno2q7Ydcj6hfBsREZEiFNxUAmmZ7gMbj+1U40ZERKQIBTeVQFR4aOnaaeRGRESkCAU3lUDXhNrERobippINFiA2MrRoIT8FNyIiIkUouKkEAqwWJiQlujxXEPBMSEokwFoo/FFwIyIiUoSCm0qib5tYXr2+Y5HRm5jIUKbf2NF1nZsj+Tk3NRuWe/9EREROFyriV4k0qlsNAwgNsjL5qrbERIbRNaF20REbANsJyDQ31dTIjYiIyEkKbiqRgqXe3RLqcJWnLRfsNkj+Egw7WAIgrE4F9VBERKTy07RUJVIQ3LjdARwgeR5MawOf3mL+bNjgpXbmcREREVFwU1kYhnHKyI2b4CZ5Hnw8FDL2Oh/PSDGPK8ARERFRcFNZbN2fxcGsXEICrbStH1m0gd0G8x8El5s05B+b/5DZTkRE5Aym4KaSKBi1ObthTUICA4o22PFL0REbJwZk7DHbiYiInMEU3FQSq7YdBKBrgpvk4KP7vLuRt+1ERESqKAU3lYBhGPxaXL5NjWjvbuZtOxERkSpKwU0lsPvwcVLSswm0Wji7YU3XjRr1gIg48LRJQ0S82U5EROQMpuCmEijIt2lbP5JqwW5KD1kDoO8z+T8UDnDyf+47xWwnIiJyBlNwUwl4Vd8GILE/DH4PqhVqFxFnHk/sX049FBEROX2oQnElsGp7Mfk2p0rsb66Kmv8QxJ0NlzxhTkVpxEZERARQcON3aRnZbDuQhcUCnRp5EdwAHN5uvjbuCQk9y61vIiIipyNNS/lZwahNq5gIIsOCvLvo0L/ma+0m5dQrERGR05eCGz/zOt/mVApuRERE3FJw42fF7idVmO0EHN5hfq/gRkREpAgFN3505Fgum1IzgRKM3GTsBnseBISYdW1ERETEiYIbP/pt+2EAmkXVoE6NEO8uKpiSqtUYrPrjExERKUy/Hf3o5H5SyrcRERHxFQU3flTifBuAQ9vMVwU3IiIiLlWK4ObVV1+lcePGhIaG0q1bN1atWuW27WeffUbnzp2pWbMm1atXp0OHDrz//vsV2FvfOJpzgg17MwDo0rg0IzcJ5dArERGR05/fg5uPPvqIcePGMWHCBNasWUP79u3p06cPaWlpLtvXrl2bRx55hBUrVvDnn38yfPhwhg8fzvfff1/BPS+b1TsOY7MbNKgdRlzNMO8v1LSUiIiIR34PbqZOncrIkSMZPnw4iYmJvP7661SrVo0ZM2a4bH/hhRdy1VVX0apVK5o2bco999xDu3btWLZsWQX3vGwc+TaN63h/kd2uaSkREZFi+DW4yc3NZfXq1fTu3dtxzGq10rt3b1asWFHs9YZhsGjRIjZv3sz555/vsk1OTg4ZGRlOX5VBqfJtMveCLQesgRDZoJx6JiIicnrza3Bz4MABbDYb0dHRTsejo6NJTU11e116ejo1atQgODiYyy+/nJdffplLLrnEZdvJkycTGRnp+GrQwP9BQXaejXW70oGSrpTKH7Wp2QgCtC2YiIiIK36fliqN8PBw1q5dy2+//cZTTz3FuHHj+Omnn1y2HT9+POnp6Y6vXbt2VWxnXVi76wi5NjtR4SE0qlPN+wuVbyMiIlIsv/7zv27dugQEBLBv3z6n4/v27SMmJsbtdVarlWbNmgHQoUMHNm7cyOTJk7nwwguLtA0JCSEkxMsCeRXk1P2kLBaL9xcquBERESmWX0dugoOD6dSpE4sWLXIcs9vtLFq0iO7du3t9H7vdTk5OTnl0sVyUKt8GFNyIiIh4we+JG+PGjWPYsGF07tyZrl27Mm3aNLKyshg+fDgAQ4cOJT4+nsmTJwNmDk3nzp1p2rQpOTk5fPvtt7z//vtMnz7dnx/DKza7wYqtB/g1f6VUp0YlDW60UkpERKQ4fg9uhgwZwv79+3nsscdITU2lQ4cOzJ8/35FkvHPnTqyn7KGUlZXFHXfcwe7duwkLC6Nly5bMmjWLIUOG+OsjeGX+hhQmfZVMSnq249gtM39jYv9E+raJLf4GhqGRGxERES9YDMMw/N2JipSRkUFkZCTp6elERERUyHvO35DC6FlrKPygC7Jtpt/YsfgAJ3Mf/O8ssFjhkX0QGFweXRUREamUSvL7+7RcLXU6sdkNJn2VXCSwARzHJn2VjM1eTIxZMGoT2UCBjYiIiAcKbsrZqm2HnKaiCjOAlPRsR5KxW5qSEhER8YqCm3KWluk+sClROwU3IiIiXlFwU86iwkN9007BjYiIiFcU3JSzrgm1iY0MxV2pPgsQGxla/DYMCm5ERES8ouCmnAVYLUxISnR5riDgmZCUSIDVQ6Viw1CNGxERES8puKkAfdvE8ur1HYuM3sREhnq3DPzYIchJByxQq3E59VJERKRq8HsRvzNFy9hwDCDIauHZQe2IiQyja0JtzyM2BQqmpCLiIci7HB4REZEzlYKbCrJ+TzoAreMjuapj/ZJd7Mi3SfBxr0RERKoeTUtVkA35wU3b+MiSX6xkYhEREa8puKkg6xXciIiIVAhNS/mK3QY7foGj+6BGNDTqAdYA85Td4K89GQC0KVNwo2kpERGR4ii48YXkeTD/QcjYe/JYRBz0fQYS+7Pj0DEyc04QEmileXSNkt9fIzciIiJe07RUWSXPg4+HOgc2ABkp5vHkeY4pqVaxEQQFlPCRHz8Mx/P3naqlkRsREZHiKLgpC7vNHLHxtOf3/If4a7cZnJQu3ya/eF+NaAgpxaiPiIjIGUbBTVns+KXoiI0TAzL2kPfvMkDJxCIiIhVBwU1ZHN3nXbMDe4DSJhNr2wUREZGSUHBTFjWivWq2My+C4DInEyvfRkRExBsKbsqiUQ9zVZSHPb+PhcWwyt6ydMnEoGkpERGRElJwUxbWAHO5N1A0wDF//i7+HuxYaRsfUbr3UHAjIiJSIgpuyiqxPwx+DyIK7ewdEQeD3+OTYx2BUiYT52RCVpr5vZaBi4iIeEXBjS8k9oexG6DjUPPnJhfB2PUYrZLYsNescVOmZOJqdSCspm/6KiIiUsUpuPEVawA0u8T8PjsdrAHsOHiMzOwTBAdaOSs6vOT31JSUiIhIiSm48aW6zc3Xg1vAME5WJo4JVzKxiIhIBVFw40u1m4DFCjkZcDSNDXvKMCUFCm5ERERKQcGNLwWGQM2G5vcH/3GM3JQqmRhUwE9ERKQUFNz4Wh1zaso48I9GbkRERPxAwY2v5efdZO7eSEb2CYIDSplMnHccMvP3rVJwIyIi4jUFN75WpxkAx1M3AdAyNpzgwFI85sPbzdfQSAir5aPOiYiIVH0Kbnwtf+Qm6PBWwEdTUhZ32zuIiIhIYQpufC0/5yYyZy9BnKCd8m1EREQqlIIbXwuPwQiuQQB2Glr2KZlYRESkgim48TWLhdyaZkDSIiC1dMnEoOBGRESklBTclIMDIWatm64RB0uXTAwKbkREREpJwU052Go3dwhvE5JWuhucyIH03eb3Cm5ERERKRMFNOVh3vC4Ajdhb8ovtNtjwGRh2CAyFsNo+7p2IiEjVpuDGxwzD4OdDZl2aWsd2lOzi5HkwrQ18Mcr8+UQ2vNjWPC4iIiJeUXDjY7sOHWd9tjlyE5hzGI4d8u7C5Hnw8VDIKDTak5FiHleAIyIi4hUFNz62fk86xwllv7WeeeDAP8VfZLfB/AcBw8XJ/GPzHzLbiYiIiEcKbnysYCfwI9UamQcOehHc7Pil6IiNEwMy9pjtRERExCMFNz5WsBO4UdvcY8qrkZuj+7y7ubftREREzmAKbnzIMAzHyE2N+FbmwYNbir+wRrR3b+BtOxERkTOYghsf2n34OOnH8wgKsFC3cWvzoDcjN416QEQc4G6DTAtExJvtRERExCMFNz5isxt8usYsvBdfK4yAemeZJw79C7YTni+2BkDfZ9yczA94+k4x24mIiIhHCm58YP6GFM57ZjHTFpqjNNsPHKPn639jCwgFex4c8aLeTWJ/GPwuWAr9kUTEweD3zPMiIiJSrEB/d+B0N39DCqNnrSmyiDslI5e/g6NoZd1p5t3UaVr8zeq1MisTW4Og/0sQ2cCcitKIjYiIiNc0clMGNrvBpK+S3Van+dcw95iy7//buxtuX2q+NjwHOlwPCT0V2IiIiJSQgpsyWLXtECnp2W7Pb80PbvZv/8u7G25fZr4mnF/WromIiJyxFNyUQVqm+8AG4F97HAABh7xYDm4YJ4ObxueVtWsiIiJnLAU3ZRAVHurxfMG0VMSx7cXf7MDfkLXf3Ak8vpMPeiciInJmUnBTBl0TahMbGeq2Os22/OAm+Ph+yM7wfLNt+fk2DbpBYIjvOikiInKGqRTBzauvvkrjxo0JDQ2lW7durFq1ym3bN998k549e1KrVi1q1apF7969PbYvTwFWCxOSEoGi5fcswFGqkR2av4FmcXtMOaakevq0jyIiImcavwc3H330EePGjWPChAmsWbOG9u3b06dPH9LS0ly2/+mnn7juuuv48ccfWbFiBQ0aNODSSy9lz549FdxzU982sUy/sSMxkc5TVDGRoUy/sSOh0S3MAwc85N0o30ZERMRnLIZhuFrJXGG6detGly5deOWVVwCw2+00aNCAu+66i4ceeqjY6202G7Vq1eKVV15h6NChxbbPyMggMjKS9PR0IiIiytx/Rz/sBqu2HSItM5uo8FC6JtQmwGqBr+6B1TPh/Afg4v+6vjhtI7x2DgSGwUM7NC0lIiJSSEl+f/u1iF9ubi6rV69m/PjxjmNWq5XevXuzYsUKr+5x7Ngx8vLyqF27tsvzOTk55OTkOH7OyCgm96WUAqwWujetU/REnebmq6c9pgpGbRoq30ZERKSs/DotdeDAAWw2G9HRzrtdR0dHk5qa6tU9HnzwQeLi4ujdu7fL85MnTyYyMtLx1aBBgzL3u0Tq5gc3nnYH3/6z+aopKRERkTLze85NWUyZMoU5c+bw+eefExrqeln2+PHjSU9Pd3zt2rWrYjtZp5n5enAr2O1Fz9vtSiYWERHxIb9OS9WtW5eAgAD27dvndHzfvn3ExMR4vPb5559nypQpLFy4kHbt2rltFxISQkiIH6d6ajYy94o6cRwydkPNhs7n92+CYwchqBrEdfRPH0VERKoQv47cBAcH06lTJxYtWuQ4ZrfbWbRoEd27d3d73bPPPssTTzzB/Pnz6dy5c0V0tfQCAqF2E/N7V3k3BaM2DbpBYHDF9UtERKSK8vu01Lhx43jzzTd599132bhxI6NHjyYrK4vhw4cDMHToUKeE42eeeYZHH32UGTNm0LhxY1JTU0lNTeXo0aP++gjF85R3o3wbERERn/LrtBTAkCFD2L9/P4899hipqal06NCB+fPnO5KMd+7cidV6MgabPn06ubm5DBo0yOk+EyZMYOLEiRXZde8V5N0UHrk5Nd9Gm2WKiIj4hN+DG4A777yTO++80+W5n376yenn7du3l3+HfM0xclMouNm/EY4fys+3Obvi+yUiIlIF+X1a6ozgqHVTaFrKUd/mHAgIqtg+iYiIVFEKbipCwchNxm7IzTp5vGCzTC0BFxER8RkFNxWhWm0Iy6+gfHCr+Wq3w47l5vcKbkRERHxGwU1FKZx3k5YMxw9DUHWI6+C3bomIiFQ1Cm4qSuG8m4Il4I26K99GRETEhxTcVJS6Bdsw5I/cOLZcUH0bERERX1JwU1FO3R1c+0mJiIiUGwU3FeXUKsX7NkD2EQiuAbEd/NkrERGRKkfBTUWplQCWAMg9Cuvnmscadjf3nhIRERGfUXBTUQKDoVYj8/u1s81X5duIiIj4nIKbilQ7P6n42EHztVEP//VFRESkilJwU1GS58HO5c7HPh5mHhcRERGfUXBTEZLnwcdDnbdeAMhMMY8rwBEREfEZBTflzW6D+Q8ChouT+cfmP2S2ExERkTJTcFPedvwCGXs9NDAgY4/ZTkRERMpMwU15O7rPt+1ERETEIwU35a1GtG/biYiIiEcKbspbox4QEQdY3DSwQES8loWLiIj4iIKb8mYNgL7P5P9QOMDJ/7nvFLOdiIiIlJmCm4qQ2B8GvwcRsc7HI+LM44n9/dMvERGRKkgbG1WUxP7Q8nJzVdTRfWaOTaMeGrERERHxMQU3FckaAAk9/d0LERGRKk3TUiIiIlKlKLgRERGRKkXBjYiIiFQpCm5ERESkSlFwIyIiIlWKghsRERGpUhTciIiISJWi4EZERESqFAU3IiIiUqWccRWKDcMAICMjw889EREREW8V/N4u+D3uyRkX3GRmZgLQoEEDP/dERERESiozM5PIyEiPbSyGNyFQFWK329m7dy/h4eFYLBaf3jsjI4MGDRqwa9cuIiIifHpvKUrPu2LpeVcsPe+KpeddsUrzvA3DIDMzk7i4OKxWz1k1Z9zIjdVqpX79+uX6HhEREfqPowLpeVcsPe+KpeddsfS8K1ZJn3dxIzYFlFAsIiIiVYqCGxEREalSFNz4UEhICBMmTCAkJMTfXTkj6HlXLD3viqXnXbH0vCtWeT/vMy6hWERERKo2jdyIiIhIlaLgRkRERKoUBTciIiJSpSi4ERERkSpFwY2PvPrqqzRu3JjQ0FC6devGqlWr/N2lKmPp0qUkJSURFxeHxWLhiy++cDpvGAaPPfYYsbGxhIWF0bt3b/755x//dPY0N3nyZLp06UJ4eDhRUVFceeWVbN682alNdnY2Y8aMoU6dOtSoUYOBAweyb98+P/X49DZ9+nTatWvnKGTWvXt3vvvuO8d5PevyNWXKFCwWC2PHjnUc0zP3nYkTJ2KxWJy+WrZs6Thfns9awY0PfPTRR4wbN44JEyawZs0a2rdvT58+fUhLS/N316qErKws2rdvz6uvvury/LPPPstLL73E66+/zq+//kr16tXp06cP2dnZFdzT09+SJUsYM2YMK1euZMGCBeTl5XHppZeSlZXlaHPvvffy1VdfMXfuXJYsWcLevXu5+uqr/djr01f9+vWZMmUKq1ev5vfff+fiiy9mwIAB/PXXX4CedXn67bff+L//+z/atWvndFzP3Ldat25NSkqK42vZsmWOc+X6rA0ps65duxpjxoxx/Gyz2Yy4uDhj8uTJfuxV1QQYn3/+ueNnu91uxMTEGM8995zj2JEjR4yQkBDjww8/9EMPq5a0tDQDMJYsWWIYhvlsg4KCjLlz5zrabNy40QCMFStW+KubVUqtWrWMt956S8+6HGVmZhrNmzc3FixYYFxwwQXGPffcYxiG/n772oQJE4z27du7PFfez1ojN2WUm5vL6tWr6d27t+OY1Wqld+/erFixwo89OzNs27aN1NRUp+cfGRlJt27d9Px9ID09HYDatWsDsHr1avLy8pyed8uWLWnYsKGedxnZbDbmzJlDVlYW3bt317MuR2PGjOHyyy93eragv9/l4Z9//iEuLo4mTZpwww03sHPnTqD8n/UZt3Gmrx04cACbzUZ0dLTT8ejoaDZt2uSnXp05UlNTAVw+/4JzUjp2u52xY8dy7rnn0qZNG8B83sHBwdSsWdOprZ536a1fv57u3buTnZ1NjRo1+Pzzz0lMTGTt2rV61uVgzpw5rFmzht9++63IOf399q1u3boxc+ZMWrRoQUpKCpMmTaJnz55s2LCh3J+1ghsRcWnMmDFs2LDBaY5cfK9FixasXbuW9PR0PvnkE4YNG8aSJUv83a0qadeuXdxzzz0sWLCA0NBQf3enyrvssssc37dr145u3brRqFEjPv74Y8LCwsr1vTUtVUZ169YlICCgSIb3vn37iImJ8VOvzhwFz1jP37fuvPNOvv76a3788Ufq16/vOB4TE0Nubi5Hjhxxaq/nXXrBwcE0a9aMTp06MXnyZNq3b8+LL76oZ10OVq9eTVpaGh07diQwMJDAwECWLFnCSy+9RGBgINHR0Xrm5ahmzZqcddZZbNmypdz/fiu4KaPg4GA6derEokWLHMfsdjuLFi2ie/fufuzZmSEhIYGYmBin55+RkcGvv/6q518KhmFw55138vnnn7N48WISEhKcznfq1ImgoCCn571582Z27typ5+0jdrudnJwcPety0KtXL9avX8/atWsdX507d+aGG25wfK9nXn6OHj3K1q1biY2NLf+/32VOSRZjzpw5RkhIiDFz5kwjOTnZuO2224yaNWsaqamp/u5alZCZmWn88ccfxh9//GEAxtSpU40//vjD2LFjh2EYhjFlyhSjZs2axpdffmn8+eefxoABA4yEhATj+PHjfu756Wf06NFGZGSk8dNPPxkpKSmOr2PHjjnajBo1ymjYsKGxePFi4/fffze6d+9udO/e3Y+9Pn099NBDxpIlS4xt27YZf/75p/HQQw8ZFovF+OGHHwzD0LOuCKeuljIMPXNfuu+++4yffvrJ2LZtm7F8+XKjd+/eRt26dY20tDTDMMr3WSu48ZGXX37ZaNiwoREcHGx07drVWLlypb+7VGX8+OOPBlDka9iwYYZhmMvBH330USM6OtoICQkxevXqZWzevNm/nT5NuXrOgPHOO+842hw/fty44447jFq1ahnVqlUzrrrqKiMlJcV/nT6N3XLLLUajRo2M4OBgo169ekavXr0cgY1h6FlXhMLBjZ657wwZMsSIjY01goODjfj4eGPIkCHGli1bHOfL81lbDMMwyj7+IyIiIlI5KOdGREREqhQFNyIiIlKlKLgRERGRKkXBjYiIiFQpCm5ERESkSlFwIyIiIlWKghsRERGpUhTciMgZyWKx8MUXX/i7GyJSDhTciEiFu/nmm7FYLEW++vbt6++uiUgVEOjvDojImalv37688847TsdCQkL81BsRqUo0ciMifhESEkJMTIzTV61atQBzymj69OlcdtllhIWF0aRJEz755BOn69evX8/FF19MWFgYderU4bbbbuPo0aNObWbMmEHr1q0JCQkhNjaWO++80+n8gQMHuOqqq6hWrRrNmzdn3rx5jnOHDx/mhhtuoF69eoSFhdG8efMiwZiIVE4KbkSkUnr00UcZOHAg69at44YbbuDaa69l48aNAGRlZdGnTx9q1arFb7/9xty5c1m4cKFT8DJ9+nTGjBnDbbfdxvr165k3bx7NmjVzeo9JkyYxePBg/vzzT/r168cNN9zAoUOHHO+fnJzMd999x8aNG5k+fTp169atuAcgIqXnk+03RURKYNiwYUZAQIBRvXp1p6+nnnrKMAxzd/JRo0Y5XdOtWzdj9OjRhmEYxhtvvGHUqlXLOHr0qOP8N998Y1itViM1NdUwDMOIi4szHnnkEbd9AIz//ve/jp+PHj1qAMZ3331nGIZhJCUlGcOHD/fNBxaRCqWcGxHxi4suuojp06c7Hatdu7bj++7duzud6969O2vXrgVg48aNtG/fnurVqzvOn3vuudjtdjZv3ozFYmHv3r306tXLYx/atWvn+L569epERESQlpYGwOjRoxk4cCBr1qzh0ksv5corr6RHjx6l+qwiUrEU3IiIX1SvXr3INJGvhIWFedUuKCjI6WeLxYLdbgfgsssuY8eOHXz77bcsWLCAXr16MWbMGJ5//nmf91dEfEs5NyJSKa1cubLIz61atQKgVatWrFu3jqysLMf55cuXY7VaadGiBeHh4TRu3JhFixaVqQ/16tVj2LBhzJo1i2nTpvHGG2+U6X4iUjE0ciMifpGTk0NqaqrTscDAQEfS7ty5c+ncuTPnnXces2fPZtWqVbz99tsA3HDDDUyYMIFhw4YxceJE9u/fz1133cVNN91EdHQ0ABMnTmTUqFFERUVx2WWXkZmZyfLly7nrrru86t9jjz1Gp06daN26NTk5OXz99deO4EpEKjcFNyLiF/Pnzyc2NtbpWIsWLdi0aRNgrmSaM2cOd9xxB7GxsXz44YckJiYCUK1aNb7//nvuueceunTpQrVq1Rg4cCBTp0513GvYsGFkZ2fzwgsvcP/991O3bl0GDRrkdf+Cg4MZP34827dvJywsjJ49ezJnzhwffHIRKW8WwzAMf3dCRORUFouFzz//nCuvvNLfXRGR05BybkRERKRKUXAjIiIiVYpybkSk0tFsuYiUhUZuREREpEpRcCMiIiJVioIbERERqVIU3IiIiEiVouBGREREqhQFNyIiIlKlKLgRERGRKkXBjYiIiFQpCm5ERESkSvl/jorzw0ybKKIAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "# Plotting model performance\n",
        "plt.plot(history.history['accuracy'], label='train_accuracy', marker='o')\n",
        "plt.plot(history.history['val_accuracy'], label='val_accuracy', marker='o')\n",
        "plt.title('Model Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Gradio Deployment"
      ],
      "metadata": {
        "id": "U_Cd8KDtoDPk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip3 install gradio"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "no_b-AcHn8iv",
        "outputId": "24757c98-4523-4570-d6b6-6c4831f55f04"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gradio\n",
            "  Downloading gradio-4.42.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting aiofiles<24.0,>=22.0 (from gradio)\n",
            "  Downloading aiofiles-23.2.1-py3-none-any.whl.metadata (9.7 kB)\n",
            "Requirement already satisfied: anyio<5.0,>=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Collecting fastapi (from gradio)\n",
            "  Downloading fastapi-0.112.1-py3-none-any.whl.metadata (27 kB)\n",
            "Collecting ffmpy (from gradio)\n",
            "  Downloading ffmpy-0.4.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting gradio-client==1.3.0 (from gradio)\n",
            "  Downloading gradio_client-1.3.0-py3-none-any.whl.metadata (7.1 kB)\n",
            "Collecting httpx>=0.24.1 (from gradio)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl.metadata (7.2 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.23.5)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.4.3)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.4)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.26.4)\n",
            "Collecting orjson~=3.0 (from gradio)\n",
            "  Downloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (24.1)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.4)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.8.2)\n",
            "Collecting pydub (from gradio)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting python-multipart>=0.0.9 (from gradio)\n",
            "  Downloading python_multipart-0.0.9-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.2)\n",
            "Collecting ruff>=0.2.2 (from gradio)\n",
            "  Downloading ruff-0.6.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting semantic-version~=2.0 (from gradio)\n",
            "  Downloading semantic_version-2.10.0-py2.py3-none-any.whl.metadata (9.7 kB)\n",
            "Collecting tomlkit==0.12.0 (from gradio)\n",
            "  Downloading tomlkit-0.12.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: typer<1.0,>=0.12 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.4)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.12.2)\n",
            "Requirement already satisfied: urllib3~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.0.7)\n",
            "Collecting uvicorn>=0.14.0 (from gradio)\n",
            "  Downloading uvicorn-0.30.6-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==1.3.0->gradio) (2024.6.1)\n",
            "Collecting websockets<13.0,>=10.0 (from gradio-client==1.3.0->gradio)\n",
            "  Downloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (3.7)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5.0,>=3.0->gradio) (1.2.2)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.7.4)\n",
            "Collecting httpcore==1.* (from httpx>=0.24.1->gradio)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl.metadata (20 kB)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx>=0.24.1->gradio)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl.metadata (8.2 kB)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.15.4)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.32.3)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2024.1)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.20.1)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0,>=0.12->gradio) (13.7.1)\n",
            "Collecting starlette<0.39.0,>=0.37.2 (from fastapi->gradio)\n",
            "  Downloading starlette-0.38.2-py3-none-any.whl.metadata (5.9 kB)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0,>=0.12->gradio) (2.16.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0,>=0.12->gradio) (0.1.2)\n",
            "Downloading gradio-4.42.0-py3-none-any.whl (16.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.8/16.8 MB\u001b[0m \u001b[31m76.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gradio_client-1.3.0-py3-none-any.whl (318 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m318.7/318.7 kB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tomlkit-0.12.0-py3-none-any.whl (37 kB)\n",
            "Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n",
            "Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m8.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading orjson-3.10.7-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.9/141.9 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_multipart-0.0.9-py3-none-any.whl (22 kB)\n",
            "Downloading ruff-0.6.2-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.3/10.3 MB\u001b[0m \u001b[31m103.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading semantic_version-2.10.0-py2.py3-none-any.whl (15 kB)\n",
            "Downloading uvicorn-0.30.6-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fastapi-0.112.1-py3-none-any.whl (93 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.2/93.2 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading ffmpy-0.4.0-py3-none-any.whl (5.8 kB)\n",
            "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading starlette-0.38.2-py3-none-any.whl (72 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m72.0/72.0 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading websockets-12.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (130 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m130.2/130.2 kB\u001b[0m \u001b[31m14.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydub, websockets, tomlkit, semantic-version, ruff, python-multipart, orjson, h11, ffmpy, aiofiles, uvicorn, starlette, httpcore, httpx, fastapi, gradio-client, gradio\n",
            "  Attempting uninstall: tomlkit\n",
            "    Found existing installation: tomlkit 0.13.2\n",
            "    Uninstalling tomlkit-0.13.2:\n",
            "      Successfully uninstalled tomlkit-0.13.2\n",
            "Successfully installed aiofiles-23.2.1 fastapi-0.112.1 ffmpy-0.4.0 gradio-4.42.0 gradio-client-1.3.0 h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 orjson-3.10.7 pydub-0.25.1 python-multipart-0.0.9 ruff-0.6.2 semantic-version-2.10.0 starlette-0.38.2 tomlkit-0.12.0 uvicorn-0.30.6 websockets-12.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
        "import gradio as gr\n",
        "import gradio as gr\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import cv2\n",
        "from tensorflow.keras.preprocessing import image"
      ],
      "metadata": {
        "id": "AHBSPlmdoRd6"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure your model is loaded here\n",
        "# model = ... # Load your trained model\n",
        "# Load your pre-trained model\n",
        "model = tf.keras.models.load_model('/content/Custom_CNN_model.keras')"
      ],
      "metadata": {
        "id": "R96cVPoloWf7"
      },
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Emotion labels dictionary\n",
        "emotion_labels = {'angry': 0, 'disgust': 1, 'fear': 2, 'happy': 5, 'neutral': 3, 'sad': 4, 'surprise': 6}\n",
        "index_to_emotion = {v: k for k, v in emotion_labels.items()}\n",
        "index_to_emotion"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wYMM-bIDoiQZ",
        "outputId": "b928ed00-325d-40a9-efe7-b886359855a8"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'angry',\n",
              " 1: 'disgust',\n",
              " 2: 'fear',\n",
              " 5: 'happy',\n",
              " 3: 'neutral',\n",
              " 4: 'sad',\n",
              " 6: 'surprise'}"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_image(img_pil):\n",
        "    \"\"\"Preprocess the PIL image to fit your model's input requirements.\"\"\"\n",
        "    # Resize the image to 48x48 pixels\n",
        "    img = img_pil.resize((48, 48))\n",
        "\n",
        "    # If the model expects grayscale images, convert the image to grayscale\n",
        "    img = img.convert('L')\n",
        "\n",
        "    # Convert the image to a numpy array\n",
        "    img_array = img_to_array(img)\n",
        "\n",
        "    # Add a batch dimension (i.e., convert the image to a 4D tensor)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "\n",
        "    # Rescale pixel values to [0, 1] (normalize the data)\n",
        "    img_array /= 255.0\n",
        "\n",
        "    return img_array"
      ],
      "metadata": {
        "id": "epgsBOodA-g5"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the Gradio interface\n",
        "def predict_emotion(image):\n",
        "    # Preprocess the image\n",
        "    processed_image = prepare_image(image)\n",
        "    # Make prediction using the model\n",
        "    prediction = model.predict(processed_image)\n",
        "    # Get the emotion label with the highest probability\n",
        "    predicted_class = np.argmax(prediction, axis=1)\n",
        "    predicted_emotion = index_to_emotion.get(predicted_class[0], \"Unknown Emotion\")\n",
        "    return predicted_emotion"
      ],
      "metadata": {
        "id": "vj_Q9TA-o0DR"
      },
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interface = gr.Interface(\n",
        "    fn=predict_emotion,  # Your prediction function\n",
        "    inputs=gr.Image(type=\"pil\"),  # Input for uploading an image, directly compatible with PIL images\n",
        "    outputs=\"text\",  # Output as text displaying the predicted emotion\n",
        "    title=\"Emotion Detection\",\n",
        "    description=\"Upload an image and see the predicted emotion.\"\n",
        ")\n",
        "\n",
        "# Launch the Gradio interface\n",
        "interface.launch()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 649
        },
        "id": "evqSKDVoo7jJ",
        "outputId": "0c64b80e-ef0b-459a-e0a5-d430319a5192"
      },
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Setting queue=True in a Colab notebook requires sharing enabled. Setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "Running on public URL: https://ed2e059a9b8bf29bea.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://ed2e059a9b8bf29bea.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UU3yCg1f2JRO"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kaggle": {
      "accelerator": "gpu",
      "dataSources": [
        {
          "datasetId": 99505,
          "sourceId": 234911,
          "sourceType": "datasetVersion"
        }
      ],
      "isGpuEnabled": true,
      "isInternetEnabled": false,
      "language": "python",
      "sourceType": "notebook"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}